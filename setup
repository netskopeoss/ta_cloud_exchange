#!/usr/bin/env python3
"""
Release checklist:

1. Set following keys in `LATEST_TAG_AND_VERSION`:
    - CORE_TAG
    - UI_TAG
    - BETA_OPT_IN
    - CORE_LATEST_VERSION_TAG
    - UI_LATEST_VERSION_TAG
    - INSTALL_VERSION
"""
from enum import Enum
from getpass import getpass
import os
import json
import argparse
import stat as st
import ipaddress
from secrets import token_bytes
from base64 import b64encode
from os import stat
import re
import socket
import shutil
import subprocess
import platform
import urllib.request
import urllib.parse
import urllib.error
import time
import multiprocessing
import sys
import random
import string
import readline
from urllib.parse import urlparse

SECRET_FILE_NAME = ".env.keys"
DEFAULT_INPUTS = {
    "CORE_TAG": {
        "default": "crestsystems/netskope:core-latest",
        "skip": True,
        "help": "",
    },
    "UI_TAG": {
        "default": "crestsystems/netskope:ui-latest",
        "skip": True,
        "help": "",
    },
    "UI_PORT": {
        "default": 80,
        "skip": False,
        "help": "",
        "user_input": "Enter the port on which you want to access the Netskope CE UI",
    },
    "JWT_SECRET": {
        "default": "",
        "skip": False,
        "help": "",
        "mandatory": True,
        "user_input": "Enter a JWT Secret which will be used for signing the authentication tokens",
    },
    "MAINTENANCE_PASSWORD": {
        "default": "",
        "skip": False,
        # "help": "Enter maintenance password that will be used for docker services. This password can be set only once. ",
        "help": "",
        "mandatory": True,
        "user_input": "Enter maintenance password that will be used for RabbitMQ and MongoDB services (This password can be set only once)",
    },
    "MAINTENANCE_PASSWORD_ESCAPED": {
        "default": "",
        "skip": True,
        "help": "Enter maintenance password that will be used for docker services. This password can be set only once.",
    },
    "WATCHTOWER_TOKEN": {"default": "token", "skip": True, "help": ""},
    "DOCKER_USERNAME": {"default": "", "skip": True, "help": ""},
    "DOCKER_PASSWORD": {"default": "", "skip": True, "help": ""},
    "MAX_MAINTENANCE_WINDOW_MINUTES": {
        "default": 15,
        "skip": True,
        "help": "",
    },
    "PULL_THREADS": {"default": 4, "skip": True, "help": ""},
    "MAX_WAIT_ON_LOCK_IN_MINUTES": {"default": 240, "skip": True, "help": ""},
    "ENABLE_TLS_V_1_2": {
        "default": "No",
        "skip": False,
        "help": "",
        "user_input": "Do you want to enable TLSv1.2 along with TLSv1.3 for CE UI",
    },
    "UI_PROTOCOL": {"default": "https", "skip": True, "help": ""},
    "REQUESTS_TIMEOUT": {"default": 300, "skip": True, "help": ""},
    "POPEN_TIMEOUT": {"default": 1800, "skip": True, "help": ""},
    "IS_MPASS_CONFIGURED": {"default": True, "skip": True, "help": ""},
    "MONGO_COMPATIBILITY": {"default": False, "skip": True, "help": ""},
    "RABBITMQ_COOKIE": {"default": "", "skip": True, "help": ""},
    "LOCATION": {"default": "", "skip": True, "help": ""},
    "COMPOSE_HTTP_TIMEOUT": {"default": 600, "skip": True, "help": ""},
    "CE_AS_VM": {"default": "False", "skip": True, "help": ""},
    "HA_ENABLED": {"default": "False", "skip": True, "help": ""},
    "CONTAINERIZATION_PLATFORM": {"default": "", "skip": True, "help": ""},
    "COMPOSE_VERSION": {"default": "", "skip": True, "help": ""},
    "HOST_OS": {"default": "", "skip": True, "help": ""},
    "PLATFORM_PROVIDER": {"default": "unknown", "skip": True, "help": ""},
    "PROMOTION_BANNERS_FILE_LOCATION": {
        "default": "https://raw.githubusercontent.com/netskopeoss/ta_cloud_exchange/main/ce_promotions.json",
        "skip": True,
        "help": "",
    },
    "CE_SETUP_ID": {"default": "", "skip": True, "help": ""},
    "CE_HEX_CODE": {"default": "", "skip": True, "help": ""},
    "CE_IV": {"default": "", "skip": True, "help": ""},
}
AVAILABLE_INPUTS = {}
LATEST_TAG_AND_VERSION = {
    "CORE_TAG": "netskopetechnicalalliances/cloudexchange:core5-5.1.1",
    "UI_TAG": "netskopetechnicalalliances/cloudexchange:ui5-5.1.1",
    "BETA_OPT_IN": "No",
    "CORE_LATEST_VERSION_TAG": "netskopetechnicalalliances/cloudexchange:core5-latest",
    "UI_LATEST_VERSION_TAG": "netskopetechnicalalliances/cloudexchange:ui5-latest",
    "INSTALL_VERSION": "5.1.1",
}
CHECKS = {}

MIN_CPU = 8
MIN_MEM_KB = 0.90 * 16 * 1024**2  # 90% of 16 GB
MEDIUM_PROFILE_REQUIREMENTS = [
    8,
    16,
    80,
    20,
]  # CPU, Memory (in GB), Disk (in GB), Free Disk (in GB)
LARGE_PROFILE_REQUIREMENTS = [
    16,
    32,
    120,
    20,
]  # CPU, Memory (in GB), Disk (in GB), Free Disk (in GB)
CE_PROFILING = {
    MEDIUM_PROFILE_REQUIREMENTS[0]: {
        "name": "Medium",
        "memory": MEDIUM_PROFILE_REQUIREMENTS[1],  # in GB
        "min_memory": MEDIUM_PROFILE_REQUIREMENTS[1]
        * 0.90
        * 1024**2,  # 90% of 16 GB
        "min_disk_bytes": MEDIUM_PROFILE_REQUIREMENTS[2]
        * 0.90
        * 1024**3,  # 90% of 80 GB
    },
    LARGE_PROFILE_REQUIREMENTS[0]: {
        "name": "Large",
        "memory": LARGE_PROFILE_REQUIREMENTS[1],  # in GB
        "min_memory": LARGE_PROFILE_REQUIREMENTS[1]
        * 0.90
        * 1024**2,  # 90% of 32 GB
        "min_disk_bytes": LARGE_PROFILE_REQUIREMENTS[2]
        * 0.90
        * 1024**3,  # 90% of 120 GB
    },
}
MIN_DISK_BYTES = 0.90 * 80 * 1024**3  # 90% of 80 GB
MIN_FREE_DISK_BYTES = 20 * 1024**3
MIN_DOCKER_VERSION = "25.0.3"
MIN_DOCKER_COMPOSE_VERSION = "2.16.0"
MIN_PODMAN_VERSION = "3.4.2"
MIN_PODMAN_COMPOSE_VERSION = "1.0.3"
MIN_OPENSSL_VERSION = "1.1.1"

N = 5
MIN_HA_SUPPORTED_VERSION = "5.0.0"
RECOMMENDED_DOCKER_VERSION = "28.0.0"
RECOMMENDED_DOCKER_COMPOSE_VERSION = "2.27.0"
RECOMMENDED_PODMAN_VERSION = "4.6.1"
RECOMMENDED_PODMAN_COMPOSE_VERSION = "1.0.6"
RECOMMENDED_HOST_OS = ["Ubuntu 20", "Ubuntu 22", "RHEL 8", "RHEL 9"]

GIT_PLUGIN_REPO = (
    "https://github.com/netskopeoss/ta_cloud_exchange_plugins.git"
)

MONGO_USER_ID = 999
MONGO_MIGRATION_TIMEOUT = 60

is_ui_running = False
is_rabbitmq_running = False
is_mongodb_running = False
is_ha = False
CONTAINERIZATION_PLATFORM = None
COMPOSE_VERSION = None
HOST_OS = None
should_ignore = False
RABBITMQ_FEATURE_FLAGS = """[classic_mirrored_queue_version,
 classic_queue_type_delivery_support,
 detailed_queues_endpoint,
 direct_exchange_routing_v2,
 drop_unroutable_metric,
 empty_basic_get_metric,
 feature_flags_v2,
 implicit_default_bindings,
 listener_records_in_ets,
 maintenance_mode_status,
 message_containers,
 quorum_queue,
 quorum_queue_non_voters,
 restart_streams,
 stream_filtering,
 stream_queue,
 stream_sac_coordinator_unblock_group,
 stream_single_active_consumer,
 stream_update_config_command,
 tracking_records_in_ets,
 user_limits,
 virtual_host_metadata].
"""


class Status(Enum):
    PASS = ("PASS",)
    NOT_VERIFIED = ("COULDN'T VERIFY",)
    FAIL = "FAIL"


def print_banner():
    print(
        f"""
  _   _        _         _                          ____  _____ 
 | \ | |  ___ | |_  ___ | | __ ___   _ __    ___   / ___|| ____|
 |  \| | / _ \| __|/ __|| |/ // _ \ | '_ \  / _ \ | |    |  _|  
 | |\  ||  __/| |_ \__ \|   <| (_) || |_) ||  __/ | |___ | |___ 
 |_| \_| \___| \__||___/|_|\_\\\___/ | .__/  \___|  \____||_____|
  ___              _          _  _  |_|    _    _               
 |_ _| _ __   ___ | |_  __ _ | || |  __ _ | |_ (_)  ___   _ __  
  | | | '_ \ / __|| __|/ _` || || | / _` || __|| | / _ \ | '_ \ 
  | | | | | |\__ \| |_| (_| || || || (_| || |_ | || (_) || | | |
 |___||_| |_||___/ \__|\__,_||_||_| \__,_| \__||_| \___/ |_| |_|

                                                          v{LATEST_TAG_AND_VERSION["INSTALL_VERSION"]}

    """
    )


def print_warning(message):
    print(f"\033[1;93m[!] \033[0;37m{message}")


def print_fail(message):
    print(f"\033[1;31m[F] \033[1;37m{message}\033[0;37m")


def print_pass(message):
    print(f"\033[0;32m[P] \033[0;37m{message}")


def compare_versions(version1, version2):
    versions1 = [int(v) for v in version1.split(".")]
    versions2 = [int(v) for v in version2.split(".")]
    for i in range(max(len(versions1), len(versions2))):
        v1 = versions1[i] if i < len(versions1) else 0
        v2 = versions2[i] if i < len(versions2) else 0
        if v1 > v2:
            return True
        elif v1 < v2:
            return False
    return True


def compare_ce_versions(v1, v2):
    """
    Compare two CE version strings.

    The version string is in the format "A.B.C" or "A.B.C-beta.D.E". The function
    first splits the string into main version and beta version. Then it compares
    the main version first, and the beta version second. If the beta version is
    not present, it is considered to be (0,).

    Returns:
        0 if the versions are equal
        -1 if v1 is less than v2
        1 if v1 is greater than v2
    """
    if not v1:
        return -1
    if not v2:
        return 1

    def version_to_tuple(version):
        parts = version.split("-")
        main_version = parts[0].split(".")
        main_version = tuple(int(part) for part in main_version)
        if len(parts) > 1:
            beta_version = parts[1].split(".")
            beta_version = tuple(
                int(part) for part in beta_version if part.isdigit()
            )
            return main_version + (0,) + beta_version
        else:
            return main_version + (1,)

    v1_tuple = version_to_tuple(v1)
    v2_tuple = version_to_tuple(v2)

    if v1_tuple == v2_tuple:
        return 0
    elif v1_tuple < v2_tuple:
        return -1
    else:
        return 1


def _get_container_name(container_info):
    container_name = container_info.get("Names", "")
    if isinstance(container_name, list):
        container_name = container_name[0]
    return container_name


def strtobool(val):
    val = val.lower()
    if val in ("y", "yes", "t", "true", "on", "1"):
        return 1
    elif val in ("n", "no", "f", "false", "off", "0"):
        return 0
    else:
        raise ValueError("invalid truth value %r" % (val,))


def ce_as_vm_check():
    return os.path.exists("/.cloud_exchange_vm.marker") and os.path.exists(
        "./ce_as_vm_tags.py"
    )


def fetch_container_info():
    global is_ui_running, is_rabbitmq_running, is_mongodb_running
    try:
        if isRedHat():
            p = subprocess.Popen(
                ["podman", "ps", "--format", "json"],
                stderr=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stdin=subprocess.PIPE,
            )
            out, err = p.communicate()
            containers = json.loads(out.decode("utf-8"))
            if err:
                raise Exception("Unable to fetch container information.")
        else:
            p = subprocess.Popen(
                ["docker", "ps", "--format", "json"],
                stderr=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stdin=subprocess.PIPE,
            )
            out, err = p.communicate()
            if err:
                raise Exception("Unable to fetch container information.")
            containers = [
                json.loads(line) for line in out.decode("utf-8").splitlines()
            ]

        for container_info in containers:
            if "_mongodb-primary" in _get_container_name(container_info):
                is_mongodb_running = True
            elif "_rabbitmq-stats" in _get_container_name(container_info):
                is_rabbitmq_running = True
            elif "_ui" in _get_container_name(container_info):
                is_ui_running = True
    except Exception:
        print_warning("Unable to fetch container information.")


def put_proxy_in_env(location=".env"):
    try:
        with open(location, "w") as f:
            for key, value in AVAILABLE_INPUTS.items():
                f.write(f"{key}={value}\n")
    except Exception as e:
        raise Exception(f"Error occurred while putting proxy variables: {e}")


def create_secret_file(passwords, location):
    mpass_without_quote = passwords["MAINTENANCE_PASSWORD"][1:-1]
    mpass = change_maintenance_password(mpass_without_quote)
    passwords["MAINTENANCE_PASSWORD"] = change_maintenance_password(passwords["MAINTENANCE_PASSWORD"])
    passwords["MAINTENANCE_PASSWORD_ESCAPED"] = change_maintenance_password(passwords["MAINTENANCE_PASSWORD_ESCAPED"])
    passwords["RABBITMQ_DEFAULT_PASS"] = mpass
    passwords["MONGO_INITDB_ROOT_PASSWORD"] = mpass
    passwords["MONGODB_PASSWORD"] = mpass

    with open(location, "w") as f:
        for key, value in passwords.items():
            f.write(f"{key}={value}\n")
    command = f"sudo chmod 400 {location}"
    set_directory_permission(location, command)


def get_secret_location(inputs):
    secret_location = SECRET_FILE_NAME
    if ce_as_vm_check():
        secret_location = f"/etc/{SECRET_FILE_NAME}"
    if "HA_IP_LIST" in inputs.keys():
        secret_location = (
            inputs.get("HA_NFS_DATA_DIRECTORY", None) + f"/{SECRET_FILE_NAME}"
            if inputs.get("HA_NFS_DATA_DIRECTORY", None)
            else None
        )
    return secret_location


def put_env_variable(inputs, location=".env"):
    inputs = dict(inputs)
    # Remove keys that are not in .env
    inputs.pop("CURRENT_DATABASE_VERSION", None)
    if location != ".env":
        inputs.pop("HA_CURRENT_NODE", None)
        inputs.pop("HA_NFS_DATA_DIRECTORY", None)
    try:
        if (
            "MAINTENANCE_PASSWORD" in inputs
            and "MAINTENANCE_PASSWORD_ESCAPED" in inputs
        ):
            inputs["IS_MPASS_CONFIGURED"] = True
        passwords = {}
        is_processed = True if inputs.get("CE_SETUP_ID", None) else False
        secret_location = get_secret_location(inputs)
        if not is_processed:
            passwords["MAINTENANCE_PASSWORD"] = (
                inputs.pop("MAINTENANCE_PASSWORD", None)
                if inputs.get("MAINTENANCE_PASSWORD", None)
                else (
                    get_existing_variable_value(secret_location, "MAINTENANCE_PASSWORD")
                    if os.path.exists(secret_location)
                    else None
                )
            )
            passwords["MAINTENANCE_PASSWORD_ESCAPED"] = (
                inputs.pop("MAINTENANCE_PASSWORD_ESCAPED", None)
                if inputs.get("MAINTENANCE_PASSWORD_ESCAPED", None)
                else (
                    get_existing_variable_value(secret_location, "MAINTENANCE_PASSWORD_ESCAPED")
                    if os.path.exists(secret_location)
                    else None
                )
            )
        if is_processed and inputs.get("MAINTENANCE_PASSWORD", None) and inputs.get("MAINTENANCE_PASSWORD_ESCAPED", None):
            passwords["MAINTENANCE_PASSWORD"] = inputs.pop("MAINTENANCE_PASSWORD", None)
            passwords["MAINTENANCE_PASSWORD_ESCAPED"] = inputs.pop("MAINTENANCE_PASSWORD_ESCAPED", None)
        if (
            passwords.get("MAINTENANCE_PASSWORD", None)
            and passwords.get("MAINTENANCE_PASSWORD_ESCAPED", None)
        ):
            if secret_location:
                create_secret_file(passwords, secret_location)
                inputs["LOCATION"] = secret_location
                AVAILABLE_INPUTS["LOCATION"] = secret_location
                inputs["CE_SETUP_ID"] = AVAILABLE_INPUTS["CE_SETUP_ID"]
                inputs["CE_HEX_CODE"] = AVAILABLE_INPUTS["CE_HEX_CODE"]
                inputs["CE_IV"] = AVAILABLE_INPUTS["CE_IV"]
        inputs.pop("MAINTENANCE_PASSWORD", None)
        inputs.pop("MAINTENANCE_PASSWORD_ESCAPED", None)
        with open(location, "w") as f:
            for key, value in inputs.items():
                f.write(f"{key}={value}\n")
    except Exception as e:
        raise Exception(f"Error occurred while putting env variables: {e}")


def create_env_if_not_exist(location=".env"):
    try:
        with open(location, "a") as f:
            pass
    except Exception as e:
        raise Exception(f"Error occurred while creating file: {e}")


def execute_shell_command(command, **kwargs):
    """Function to exectute shell command using python script."""
    p = None
    try:
        p = subprocess.check_output(command, shell=True, **kwargs)
        return p
    except Exception as e:
        if p:
            p.kill()
        raise Exception(f"Error occurred while executing command. Error: {e}")


def create_mongo_container(
    deployment,
    maintenance_password,
    http_proxy,
    https_proxy,
    temp_container_name,
    image_name,
):
    """Create MongoDB container."""
    create_container = f"{deployment} run -d -t -e MONGODB_ADVERTISED_HOSTNAME=mongodb-primary \
                        -e MONGO_INITDB_ROOT_USERNAME=root \
                        -e MONGO_INITDB_ROOT_PASSWORD={maintenance_password} \
                        -e MONGO_INITDB_DATABASE=cte \
                        -e MONGODB_USERNAME=cteadmin \
                        -e MONGODB_PASSWORD={maintenance_password} \
                        -e HTTP_PROXY=${http_proxy} \
                        -e HTTPS_PROXY=${https_proxy} \
                        -v ./data/mongo-data/data/db:/data/db:z \
                        --name {temp_container_name} \
                        index.docker.io/{image_name} >/dev/null 2>&1"
    execute_shell_command(create_container)


def remove_mongo_contianer(deployment, temp_mongo_container_name):
    """Remove mongodb contianer."""
    remove_container = (
        f"{deployment} rm -f {temp_mongo_container_name} >/dev/null 2>&1"
    )
    execute_shell_command(remove_container)
    time.sleep(5)


def execute_mongodb_command(
    deployment,
    temp_mongo_container_name,
    shell,
    maintenance_password,
    eval_command,
    **kwargs,
):
    """Execute command inside mongodb contianer."""
    compatibility_command = f"{deployment} exec {temp_mongo_container_name} {shell} -u root --password {maintenance_password} admin --eval {eval_command}"
    execute_shell_command(compatibility_command, **kwargs)


def run_temp_mongo_container_for_migration(
    maintenance_password, http_proxy, https_proxy
):
    """Migrate mongo data by running temp mongo container and update featurecompatibilityversion variable from mongo."""
    deployment = None
    MONGO_MIGRATE_IMAGE = "mongo:5.0.21"
    MONGO_CURRENT_IMAGE = "mongo:6.0.12"
    temp_mongo_container_name = "mongo-migration"

    if isRedHat():
        deployment = "podman"
    else:
        deployment = "docker"

    # If from previous temp container is still running then kill that container and start again.
    remove_mongo_contianer(deployment, temp_mongo_container_name)

    # create mongo contianer
    create_mongo_container(
        deployment,
        maintenance_password,
        http_proxy,
        https_proxy,
        temp_mongo_container_name,
        MONGO_MIGRATE_IMAGE,
    )
    try:
        time.sleep(MONGO_MIGRATION_TIMEOUT // 2)
        eval_command = (
            """'db.adminCommand({setFeatureCompatibilityVersion: "5.0"})'"""
        )
        execute_mongodb_command(
            deployment,
            temp_mongo_container_name,
            "mongo",
            maintenance_password,
            eval_command,
            stderr=subprocess.PIPE,
        )
    except Exception:
        # remove above container
        time.sleep(MONGO_MIGRATION_TIMEOUT // 2)
        remove_mongo_contianer(deployment, temp_mongo_container_name)
        # spin latest mongo version to check compatibility
        create_mongo_container(
            deployment,
            maintenance_password,
            http_proxy,
            https_proxy,
            temp_mongo_container_name,
            MONGO_CURRENT_IMAGE,
        )

        time.sleep(MONGO_MIGRATION_TIMEOUT // 2)
        eval_command = """'db.adminCommand({getParameter: 1, featureCompatibilityVersion: 1})'"""
        execute_mongodb_command(
            deployment,
            temp_mongo_container_name,
            "mongosh",
            maintenance_password,
            eval_command,
        )

    time.sleep(MONGO_MIGRATION_TIMEOUT // 2)
    remove_mongo_contianer(deployment, temp_mongo_container_name)

    print_pass("The migration of database has been successfully completed.")


def get_all_existed_env_variable(location=".env", override=True):
    try:
        if not os.path.exists(location):
            return
        with open(location, "r") as f:
            if os.stat(location).st_size > 0:
                with open(f"{location}.{int(time.time())}", "w+") as backup:
                    for line in f.readlines():
                        backup.write(line)
                        key, value = line.split("=", 1)
                        if override or key not in AVAILABLE_INPUTS:
                            AVAILABLE_INPUTS[key] = value.strip()

        if AVAILABLE_INPUTS.get("HTTPS_PROXY"):
            AVAILABLE_INPUTS["CORE_HTTP_PROXY"] = AVAILABLE_INPUTS[
                "HTTPS_PROXY"
            ]
            AVAILABLE_INPUTS["CORE_HTTPS_PROXY"] = AVAILABLE_INPUTS[
                "HTTPS_PROXY"
            ]

            AVAILABLE_INPUTS.pop("HTTP_PROXY", None)
            AVAILABLE_INPUTS.pop("HTTPS_PROXY", None)
        if AVAILABLE_INPUTS.get("RABBITMQ_CUSTOM_CONF_PATH"):
            AVAILABLE_INPUTS.pop("RABBITMQ_CUSTOM_CONF_PATH", None)
    except Exception as e:
        raise Exception(f"Error occurred while getting env variables: {e}")


def set_directory_permission(directory, command):
    p = None
    try:
        p = subprocess.Popen(
            command.split(),
            stderr=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stdin=subprocess.PIPE,
        )
        out, err = p.communicate()
        if len(err) <= 0:
            return
        else:
            raise Exception(err.decode("utf-8"))
    except Exception as e:
        if p:
            p.kill()
        raise Exception(
            f"Error occurred while setting file permissions for {directory}. Error: {e}"
        )


def _get_cert_location():
    cert_file = "data/ssl_certs/cte_cert.crt"
    key_file = "data/ssl_certs/cte_cert_key.key"
    if AVAILABLE_INPUTS.get("HA_NFS_DATA_DIRECTORY"):
        cert_file = f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/config/ssl_certs/cte_cert.crt"
        key_file = f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/config/ssl_certs/cte_cert_key.key"
    return cert_file, key_file


def check_for_certs():
    try:
        cert_file, key_file = _get_cert_location()
        if os.path.isfile(cert_file) and os.path.isfile(key_file):
            return True
        return False
    except Exception as e:
        raise Exception(
            f"Error occurred while checking for SSL certs. Error: {e}"
        )


def create_self_signed_ssl_certs():
    try:
        cert_file, key_file = _get_cert_location()
        print(
            f"Generating self signed certificate with validity of one year..."
        )
        command = f"openssl req -x509 -newkey rsa:4096 -keyout {key_file} -out {cert_file} -sha256 -days 365 -nodes -subj /CN=localhost -extensions extendedkeyusage -config data/ssl_certs/extendedkeyusage.txt"
        p = subprocess.Popen(
            command.split(),
            stderr=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stdin=subprocess.PIPE,
        )
        out, err = p.communicate()
        if p.returncode == 0:
            print(f"{err.decode('utf-8')}\n")
            command = f"sudo chmod 644 {cert_file}"
            set_directory_permission(cert_file, command)
            command_key = f"sudo chmod 644 {key_file}"
            set_directory_permission(key_file, command_key)
        else:
            raise Exception(f"{err.decode('utf-8')}\n")
    except Exception as e:
        p.kill()
        raise Exception(
            f"Error occurred while generating self-signed ssl certificates. Error: {e}"
        )


def check_port_for_ha(ip, port, timeout=3):
    """
    Check if a specific port on a given IP is reachable.

    Args:
    ip (str): The IP address to check.
    port (int): The port number to check.
    timeout (int): Timeout for the connection attempt in seconds.

    Returns:
    tuple: A tuple containing the following elements:
    - is_port_open (bool): True if the port is open, False otherwise.
    - is_service_running (bool): True if the service is running, False otherwise.
    """
    # Create a socket object
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.settimeout(timeout)
    is_port_open = False
    is_service_running = False
    try:
        # Try to connect to the given IP and port
        sock.connect((ip, port))
        try:
            # Try to send some data to see if the service responds
            sock.sendall(b"Hello")
            data = sock.recv(1024)
            if data:
                is_port_open = True
                is_service_running = True
            else:
                is_port_open = True
                is_service_running = False
        except socket.error:
            is_port_open = True
            is_service_running = False
    except socket.timeout:
        is_port_open = False
        is_service_running = False
    except socket.error as e:
        if e.errno == 111:  # Connection refused
            is_port_open = True
            is_service_running = False
        else:
            is_port_open = False
            is_service_running = False
    finally:
        sock.close()
    return is_port_open, is_service_running


def check_for_ha_ports():
    try:
        port_flag = True
        for port in [4369, 5672, 15672, 25672, 35672]:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            result = sock.connect_ex(("127.0.0.1", port))
            if result == 0:
                if is_rabbitmq_running:
                    print_warning("RabbitMQ container is already running.")
                    break
                else:
                    print_fail(f"Port {port} is already in use.")
                    port_flag = False
            else:
                print_pass(f"Port {port} is available.")

        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        result = sock.connect_ex(("127.0.0.1", 27017))
        if result == 0:
            if is_mongodb_running:
                print_warning("MongoDB container is already running.")
            else:
                print_fail(f"Port 27017 is already in use.")
                port_flag = False
        else:
            print_pass(f"Port 27017 is available.")

        CHECKS["Port Check"] = Status.PASS if port_flag else Status.FAIL
    except Exception as e:
        # print(e)
        print_warning(f"Could not verify Port information of the machine")
        CHECKS["Port Check"] = Status.NOT_VERIFIED
    port_error_msg = False
    for host in AVAILABLE_INPUTS.get("HA_IP_LIST", "").split(","):
        if host != AVAILABLE_INPUTS.get("HA_CURRENT_NODE"):
            for port in [4369, 5672, 15672, 25672, 35672, 27017]:
                is_port_open, _ = check_port_for_ha(host, port)
                if not is_port_open:
                    print_fail(
                        f"Port {port} of {host} is not reachable from {AVAILABLE_INPUTS.get('HA_CURRENT_NODE')}"
                    )
                    port_error_msg = True
                else:
                    print_pass(
                        f"Port {port} of {host} is reachable from {AVAILABLE_INPUTS.get('HA_CURRENT_NODE')}"
                    )
    if port_error_msg:
        print(
            "\033[1;31mPlease ensure all HA nodes are reachable from each other.\033[0;37m"
        )
        CHECKS["Port Check"] = Status.FAIL


def print_sizing_table(actual):
    """Print the sizing table."""
    metrics = ["Cores", "RAM (GB)", "Disk Space (GB)", "Free Space (GB)"]
    print(
        "+-----------------+---------------+-----------------+-----------------+"
    )
    print(
        f"| {'Metric':<15} | {'Current':<13} | {'Medium Profile':<15} | {'Large Profile':<15} |"
    )
    print(
        "+-----------------+---------------+-----------------+-----------------+"
    )

    # Print the data rows
    for i in range(len(metrics)):
        print(
            f"| {metrics[i]:<15} | {str(actual[i]):<13} | {str(MEDIUM_PROFILE_REQUIREMENTS[i]):<15} | {str(LARGE_PROFILE_REQUIREMENTS[i]):<15} |"
        )
        print(
            "+-----------------+---------------+-----------------+-----------------+"
        )


def check_machine_specs():
    print("\nVerifying minimum system requirements...")
    print(
        '\033[1;37mNOTE: The actual system requirements depend on several criteria including data volume, # of plugins among others.\nIt is highly recommended to refer to the System Requirements section of the "User Guide".\n'
        + "CE sizing profile is decided based on number of CPU(s) on the machine. 8 CPUs are required for the medium profile and 16 CPUs are required for the large profile.\033[0;37m"
    )

    # Check CPUs
    try:
        profile_name = None
        cpu_cores = multiprocessing.cpu_count()
        if cpu_cores not in CE_PROFILING:
            CHECKS["CPU Check"] = Status.FAIL
        else:
            profile_name = CE_PROFILING[cpu_cores]["name"]
            CHECKS["CPU Check"] = Status.PASS
    except Exception as e:
        print_warning(f"Could not verify CPU information of the machine...")
        CHECKS["CPU Check"] = Status.NOT_VERIFIED

    # Check Memory
    try:
        total_memory = None
        with open("/proc/meminfo", "r") as f:
            lines = f.readlines()
            for line in lines:
                if line.startswith("MemTotal"):
                    memory = int(line.split()[1])
                    total_memory = round(memory / 1024**2, 1)
                    memory_pass = False
                    if cpu_cores in CE_PROFILING:
                        if memory < CE_PROFILING[cpu_cores]["min_memory"]:
                            CHECKS["Memory Check"] = Status.FAIL
                        else:
                            memory_pass = True
                    else:
                        CHECKS["Memory Check"] = Status.FAIL
                    if memory_pass:
                        CHECKS["Memory Check"] = Status.PASS
                    break
    except Exception as e:
        # print(e)
        print_warning(f"Could not verify Memory information of the machine")
        CHECKS["Memory Check"] = Status.NOT_VERIFIED

    # Check Disk Space
    try:
        # Get the path of the current file
        current_file_path = __file__
        # Get the directory of the current file
        current_dir = os.path.dirname(current_file_path) or os.getcwd()
        disk_stats = shutil.disk_usage(current_dir)
        free_space = disk_stats.free
        total_space = disk_stats.total
        disk_space_check_pass = False
        if cpu_cores in CE_PROFILING:
            min_disk_bytes = CE_PROFILING[cpu_cores]["min_disk_bytes"]
            if total_space < min_disk_bytes:
                CHECKS["Disk Space Check"] = Status.FAIL
            else:
                disk_space_check_pass = True
        else:
            CHECKS["Disk Space Check"] = Status.FAIL

        if disk_space_check_pass:
            CHECKS["Disk Space Check"] = Status.PASS
        try:
            if free_space < MIN_FREE_DISK_BYTES:
                CHECKS["Free Disk Space Check"] = Status.FAIL
            else:
                CHECKS["Free Disk Space Check"] = Status.PASS
        except Exception as e:
            print_warning(f"Could not verify Disk information of the machine")
            CHECKS["Free Disk Space Check"] = Status.NOT_VERIFIED
    except Exception as e:
        # print(e)
        print_warning(f"Could not verify Disk information of the machine")
        CHECKS["Disk Space Check"] = Status.NOT_VERIFIED

    matched = not (
        Status.FAIL
        in [
            CHECKS.get("CPU Check"),
            CHECKS.get("Memory Check"),
            CHECKS.get("Disk Space Check"),
            CHECKS.get("Free Disk Space Check"),
        ]
    )
    sizing_result = None
    if not profile_name and cpu_cores < MEDIUM_PROFILE_REQUIREMENTS[0]:
        profile_name = CE_PROFILING[MEDIUM_PROFILE_REQUIREMENTS[0]]["name"]
    elif not profile_name:
        profile_name = CE_PROFILING[LARGE_PROFILE_REQUIREMENTS[0]]["name"]
    if matched:
        sizing_result = (
            f"\033[0;32mMatched with {profile_name} profile\033[0;37m"
        )
    else:
        sizing_result = (
            f"\033[1;31mFailed for {profile_name} profile\033[0;37m"
        )
    print("\nCE Sizing Profile Check:", sizing_result, end="\n\n")
    if not matched:
        machine_specs = [
            cpu_cores,
            total_memory,
            round(total_space / 1024**3, 1),
            round(free_space / 1024**3, 1),
        ]
        print_sizing_table(machine_specs)

    # Check port availability
    if is_ha or (
        AVAILABLE_INPUTS.get("HA_IP_LIST")
        and AVAILABLE_INPUTS.get("HA_CURRENT_NODE")
    ):
        check_for_ha_ports()

    if Status.FAIL in [
        CHECKS.get("Memory Check"),
        CHECKS.get("Disk Space Check"),
        CHECKS.get("Free Disk Space Check"),
        CHECKS.get("CPU Check"),
        CHECKS.get("Port Check"),
    ]:
        print(
            "\033[1;31mOne or more system requirement checks have failed. Please ensure the minimum system requirements are met to proceed further. \033[0;37m"
        )

    global should_ignore
    if not should_ignore and Status.FAIL in [
        CHECKS.get("Memory Check"),
        CHECKS.get("Disk Space Check"),
        CHECKS.get("Free Disk Space Check"),
        CHECKS.get("CPU Check"),
        CHECKS.get("Port Check"),
    ]:
        exit(1)


def check_docker_versions():
    try:
        global CONTAINERIZATION_PLATFORM, COMPOSE_VERSION
        regex = r"(\d+(\.\d+){2,3})"
        command = "docker --version"
        p = subprocess.check_output(command, shell=True)
        docker_version = re.search(regex, p.decode("utf-8")).groups()[0]
        CONTAINERIZATION_PLATFORM = "Docker " + docker_version
        if compare_versions(docker_version, MIN_DOCKER_VERSION):
            print_pass(f"Docker Version {docker_version}")
            CHECKS["Docker"] = Status.PASS
        else:
            print_fail(
                f"Docker Version {docker_version} (Minimum {MIN_DOCKER_VERSION} is required)"
            )
            CHECKS["Docker"] = Status.FAIL
        if docker_version != RECOMMENDED_DOCKER_VERSION:
            print_warning(
                f"The recommended docker version is {RECOMMENDED_DOCKER_VERSION}"
            )

        command = "docker compose version"
        p = subprocess.check_output(command, shell=True)
        docker_compose_version = re.search(regex, p.decode("utf-8")).groups()[
            0
        ]
        COMPOSE_VERSION = "docker compose " + docker_compose_version
        if compare_versions(
            docker_compose_version, MIN_DOCKER_COMPOSE_VERSION
        ):
            print_pass(f"Docker Compose Version {docker_compose_version}")
            CHECKS["Docker-Compose"] = Status.PASS
        else:
            print_fail(
                f"Docker Compose Version {docker_compose_version} (Minimum {MIN_DOCKER_COMPOSE_VERSION} is required)"
            )
            CHECKS["Docker-Compose"] = Status.FAIL
        if docker_compose_version != RECOMMENDED_DOCKER_COMPOSE_VERSION:
            print_warning(
                f"The recommended docker compose version is {RECOMMENDED_DOCKER_COMPOSE_VERSION}"
            )

    except Exception as e:
        CHECKS["Docker-Compose"] = Status.NOT_VERIFIED
        CHECKS["Docker"] = Status.NOT_VERIFIED
        raise Exception("Docker not found")


def check_podman_versions():
    try:
        global CONTAINERIZATION_PLATFORM, COMPOSE_VERSION
        regex = r"(\d+(\.\d+){2,3})"
        command = "podman-compose --version"
        p = subprocess.check_output(command, shell=True)
        lines = p.decode("utf-8").splitlines()

        podman_version = ""
        for line in lines:
            if "podman version" in line:
                podman_version = re.search(regex, line).groups()[0]
                break

        if podman_version == "":
            raise
        CONTAINERIZATION_PLATFORM = "Podman " + podman_version
        if compare_versions(podman_version, MIN_PODMAN_VERSION):
            print_pass(f"Podman Version {podman_version}")
            CHECKS["Podman"] = Status.PASS
        else:
            print_fail(
                f"Podman Version {podman_version} (Minimum {MIN_PODMAN_VERSION} is required)"
            )
            CHECKS["Podman"] = Status.FAIL
        if podman_version != RECOMMENDED_PODMAN_VERSION:
            print_warning(
                f"The recommended podman version is {RECOMMENDED_PODMAN_VERSION}"
            )

        podman_compose_version = ""
        for line in lines:
            if "podman-compose" in line:
                podman_compose_version = re.search(regex, line).groups()[0]
                break

        if podman_compose_version == "":
            raise
        COMPOSE_VERSION = "podman-compose " + podman_compose_version
        if compare_versions(
            podman_compose_version, MIN_PODMAN_COMPOSE_VERSION
        ):
            print_pass(f"Podman Compose Version {podman_compose_version}")
            CHECKS["Podman-Compose"] = Status.PASS
        else:
            print_fail(
                f"Podman Compose Version {podman_compose_version} (Minimum {MIN_PODMAN_COMPOSE_VERSION} is required)"
            )
            CHECKS["Podman-Compose"] = Status.FAIL
        if podman_compose_version != RECOMMENDED_PODMAN_COMPOSE_VERSION:
            print_warning(
                f"The recommended podman-compose version is {RECOMMENDED_PODMAN_COMPOSE_VERSION}"
            )

        command = "rpm -qa"
        p = subprocess.check_output(command, shell=True)
        lines = p.decode("utf-8").splitlines()

        is_plugin_present = False
        for line in lines:
            if line.startswith("podman-plugins"):
                is_plugin_present = True
                break

        if is_plugin_present:
            print_pass(f"Verified podman plugins are installed")
            CHECKS["Podman-Plugin"] = Status.PASS
        else:
            print_fail(
                f"Required podman plugins are not installed. (Run `yum install podman-plugins` and Re-run the script)"
            )
            CHECKS["Podman-Plugin"] = Status.FAIL

    except Exception as e:
        # print(e)
        CHECKS["Podman-Compose"] = Status.NOT_VERIFIED
        CHECKS["Podman-Plugin"] = Status.NOT_VERIFIED
        CHECKS["Podman"] = Status.NOT_VERIFIED
        raise Exception("Podman not found")


def validate_proxy(proxy, cur_proxy=None):
    if proxy == "" and cur_proxy is not None and len(cur_proxy) > 0:
        return True
    regex = r"^(?:(.*))://(?:(.*))$"
    result = re.search(regex, proxy)
    if result is None:
        print("Invalid Proxy Provided...")
        return False
    parts = result.groups()
    if len(parts) < 2:
        print("Invalid Proxy Provided...")
        return False
    if parts[0] not in ["http", "https"]:
        print("Invalid Protocol Provided... Valid Protocols are http/https...")
        return False
    if parts[1] == " ":
        print("Invalid Hostname Provided... It should be valid IP/FQDN...")
        return False
    return True


def prepare_proxy(url, username=None, password=None):
    if (
        username is None
        or len(username) == 0
        or password is None
        or len(password) == 0
    ):
        return url
    prefix = "https://" if url.startswith("https://") else "http://"
    url = url.replace(prefix, "")

    username = urllib.parse.quote_plus(username)
    password = urllib.parse.quote_plus(password)
    return f"{prefix}{username}:{password}@{url}"


def parse_proxy(url):
    if url is None or len(url) == 0:
        return None

    url = urllib.parse.urlparse(url)
    if url.scheme is None:
        return f"{url.hostname}"
    if url.port is None:
        return f"{url.scheme}://{url.hostname}"
    return f"{url.scheme}://{url.hostname}:{url.port}"


def set_ce_version_for_vm():
    try:
        from ce_as_vm_tags import CORE_TAG, UI_TAG

        AVAILABLE_INPUTS["CORE_TAG"] = CORE_TAG
        AVAILABLE_INPUTS["UI_TAG"] = UI_TAG
    except Exception:
        pass


def ask_for_initial_inputs():
    isProxy = (
        input(
            "\n\nAre you using HTTP(s) proxy for outbound traffic? [y/n]\n> "
        )
        .strip()
        .lower()
    )

    if isProxy == "y" or isProxy == "yes":
        # HTTPS_PROXY
        cur_https_proxy = parse_proxy(
            AVAILABLE_INPUTS.get("CORE_HTTPS_PROXY", None)
        )

        print(
            f"\nEnter Proxy URL (e.g. http(s)://10.0.0.0:3128)  {('(Current: ' + cur_https_proxy + ')') if cur_https_proxy is not None else ''}"
        )
        https_proxy = input("> ").strip()
        https_proxy_password = None
        while not validate_proxy(https_proxy, cur_https_proxy):
            print(
                f"\nEnter Proxy URL (e.g. http(s)://10.0.0.0:3128)  {('(Current: ' + cur_https_proxy + ')') if cur_https_proxy is not None else ''}"
            )
            https_proxy = input("> ").strip()
        if https_proxy is None or len(https_proxy) == 0:
            https_proxy = cur_https_proxy

        https_proxy_username = input(
            f"Enter proxy username (skip in case of unauthenticated proxy):\n> "
        ).strip()
        if https_proxy_username is not None and len(https_proxy_username) > 0:
            https_proxy_password = getpass(
                "Enter proxy password: \n> "
            ).strip()
            while https_proxy_password == "":
                print("Proxy password can not be empty... Please try again.\n")
                https_proxy_password = getpass(
                    "Enter proxy password: \n> "
                ).strip()

        AVAILABLE_INPUTS["CORE_HTTPS_PROXY"] = prepare_proxy(
            https_proxy,
            username=https_proxy_username,
            password=https_proxy_password,
        )
        AVAILABLE_INPUTS["CORE_HTTP_PROXY"] = AVAILABLE_INPUTS[
            "CORE_HTTPS_PROXY"
        ]

        print(
            "\n\033[1;37mNOTE: These proxy details will be reflected on the Settings > General > Proxy page on Netskope CE UI.\n\033[0;37m"
        )
    else:
        AVAILABLE_INPUTS["CORE_HTTP_PROXY"] = ""
        AVAILABLE_INPUTS["CORE_HTTPS_PROXY"] = ""

    tenant_name = ""
    while True:
        tenant_name = input(
            "\n> Please enter the Netskope Tenant URL (e.g. https://demo.goskope.com)\nPlease Enter 'test' if you do not have any Netskope tenant: "
        ).strip()
        if tenant_name == "test":
            break
        if not tenant_name:
            print_fail(
                "Tenant URL can not be empty. Please provide full tenant URL (e.g. https://demo.goskope.com)."
            )
            continue
        tenant_name = tenant_name.strip().rstrip("/")
        result = urlparse(tenant_name)
        if result.scheme.lower() != "https":
            print_fail(
                "Tenant URL schema must be https. Please provide full tenant URL (e.g. https://demo.goskope.com)."
            )
        elif (
            result.path != ""
            or result.params != ""
            or result.query != ""
            or result.fragment != ""
        ):
            print_fail(
                "Invalid Tenant URL provided. Please provide full tenant URL (e.g. https://demo.goskope.com)."
            )
        else:
            break
    AVAILABLE_INPUTS["NETSKOPE_TENANT"] = tenant_name


class ClientExceptions(Exception):
    pass


class ServerExceptions(Exception):
    pass


def handle_http_errors(res):
    status_code = res.code
    if status_code == 200:
        # raise ClientExceptions("Request Timeout Error.")
        return

    # Client Errors
    elif status_code == 400:
        raise ClientExceptions("Bad Request Error.")
    elif status_code == 401:
        raise ClientExceptions("Unauthorized Error.")
    elif status_code == 403:
        raise ClientExceptions("Forbidden Error.")
    elif status_code == 404:
        raise ClientExceptions("Not Found Error.")
    elif status_code == 408:
        raise ClientExceptions("Request Timeout Error.")

    # Server Errors
    elif status_code == 500:
        raise ServerExceptions("Internal Server Error.")
    elif status_code == 502:
        raise ServerExceptions("Bad Gateway Error.")
    elif status_code == 503:
        raise ServerExceptions("Service Unavailable Error.")
    elif status_code == 504:
        raise ServerExceptions("Gateway Timeout Error.")


def connectivity_check_for_analytics():
    try:
        connectivity = True
        print()
        url = "https://reporting.netskope.tech/"
        req = urllib.request.Request(url)
        proxy = None
        if AVAILABLE_INPUTS.get("CORE_HTTPS_PROXY", "") != "":
            proxy = AVAILABLE_INPUTS.get("CORE_HTTPS_PROXY")
        proxies = {}
        if proxy is not None:
            proxies["https"] = proxy
        proxy_support = urllib.request.ProxyHandler(proxies=proxies)
        opener = urllib.request.build_opener(proxy_support)
        urllib.request.install_opener(opener)
        urllib.request.urlopen(req, timeout=60)
    except urllib.error.HTTPError as e:
        if e.code not in [400, 401, 403]:
            connectivity = False
            print_warning(
                f"Error occurred while verifying connectivity to {url}: {e}"
            )
    except Exception as e:
        connectivity = False
        print_warning(
            f"Error occurred while verifying connectivity to {url}: {e}"
        )
    if not connectivity:
        print_warning(
            "Unable to establish a connection with https://reporting.netskope.tech/. "
            "Verify the network connectivity, proxy settings or firewall configurations "
            "to address the connectivity issues for enhanced product deployment and administration experience."
        )
    AVAILABLE_INPUTS["ANALYTICS_SERVER_CONNECTIVITY"] = connectivity


def handle_connectivity(name, url):
    try:
        req = urllib.request.Request(url)
        proxy = None
        if AVAILABLE_INPUTS.get("CORE_HTTPS_PROXY", "") != "":
            proxy = AVAILABLE_INPUTS.get("CORE_HTTPS_PROXY")

        proxies = {}

        if proxy is not None:
            proxies["https"] = proxy

        proxy_support = urllib.request.ProxyHandler(proxies=proxies)
        opener = urllib.request.build_opener(proxy_support)
        urllib.request.install_opener(opener)

        res = urllib.request.urlopen(req, timeout=60)
        handle_http_errors(res)
        CHECKS[name] = Status.PASS
        print_pass(f"Connectivity to {url} verified successfully.")
    except ClientExceptions as e:
        print_fail(
            f"Error occurred while verifying connectivity to {url}: ClientError {e}"
        )
        CHECKS[name] = Status.FAIL
        raise
    except ServerExceptions as e:
        print_fail(
            f"Error occurred while verifying connectivity to {url}: ServerError {e}"
        )
        CHECKS[name] = Status.FAIL
        raise
    except urllib.error.HTTPError as e:
        print_fail(
            f"Error occurred while verifying connectivity to {url}: HTTPError {e}"
        )
        CHECKS[name] = Status.FAIL
        raise
    except urllib.error.URLError as e:
        print_fail(
            f"Error occurred while verifying connectivity to {url}: URLError {e}"
        )
        CHECKS[name] = Status.FAIL
        raise
    except Exception as e:
        print_fail(
            f"Error occurred while verifying connectivity to {url}: {e}"
        )
        CHECKS[name] = Status.FAIL
        raise


def timeout(t, cmd, *args):
    pool = multiprocessing.Pool(processes=1)
    result = pool.apply_async(cmd, args=args)
    try:
        retval = result.get(timeout=t)
    except multiprocessing.TimeoutError as err:
        pool.terminate()
        pool.join()
        url = ""
        if len(args) == 0:
            CHECKS["Github"] = Status.FAIL
            url = "https://github.com"
        else:
            CHECKS[args[0]] = Status.FAIL
            url = args[1]
        print_fail(
            f"Error occurred while verifying connectivity to {url}: Timed out."
        )
    except Exception as err:
        if len(args) == 0:
            CHECKS["Github"] = Status.FAIL
        else:
            CHECKS[args[0]] = Status.FAIL
    else:
        return retval


def check_connectivity():
    # Check connectivity for github, docker, tenant and analytics url
    print(
        "\nVerifying the connectivity for pre-requisite outbound network calls..."
    )

    if not ce_as_vm_check():
        timeout(
            60, handle_connectivity, "Docker Hub", "https://hub.docker.com"
        )

        print(
            "\033[1;37mNOTE: This connectivity check is only for the Docker Hub (https://hub.docker.com). Docker images are pulled from CDN. Please make sure that you have the required connectivity to pull the docker images.\033[0;37m"
        )

    tenant_name = AVAILABLE_INPUTS.get("NETSKOPE_TENANT")
    if tenant_name != "test":
        timeout(
            60,
            handle_connectivity,
            "Netskope tenant",
            tenant_name,
        )

    if Status.FAIL in [
        CHECKS.get("Github"),
        CHECKS.get("Docker Hub"),
        CHECKS.get("Netskope tenant"),
    ]:
        print(
            "\033[1;31mOne or more connectivity checks have failed. Verify the network connectivity, proxy settings or firewall configurations to address the connectivity issues. \033[0;37m"
        )
    else:
        put_proxy_in_env()
        connectivity_check_for_analytics()


def isRedHat():
    try:
        with open("/etc/redhat-release") as f:
            content = f.readline()
            if content.startswith("Red Hat"):
                return True
            else:
                return False
    except Exception as e:
        return False


def isRedHat79():
    try:
        with open("/etc/redhat-release") as f:
            content = f.readline()
            if content.startswith("Red Hat") and "7.9" in content:
                return True
            else:
                return False
    except Exception as e:
        return False


def check_prerequisites():
    check_connectivity()
    check_machine_specs()
    print("\nVerifying docker/podman prerequisites...")
    if isRedHat79():
        try:
            check_docker_versions()
        except Exception as e:
            print_fail(
                f"Could not verify Docker/Docker compose version of the machine"
            )
    elif isRedHat():
        try:
            check_podman_versions()
        except Exception as e:
            print_fail(
                f"Could not verify Podman/Podman-compose/Podman-plugins version of the machine"
            )
    else:
        try:
            check_docker_versions()
        except Exception as e:
            try:
                check_podman_versions()
            except Exception as e:
                print_fail(
                    f"Could not verify Docker/Docker compose version of the machine"
                )
                print_fail(
                    f"Could not verify Podman/Podman-compose/Podman-plugins version of the machine"
                )
    print("\nVerifying OpenSSL prerequisites...")
    try:
        process = subprocess.Popen(['openssl', 'version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        output, error = process.communicate()
        if process.returncode == 0:
            match = re.search(r'^openssl\s*(\d+\.\d+\.\d+)', output.decode("utf-8"), re.IGNORECASE)
            full_version_match = re.search(r'^openssl\s*([\d.]+[a-z]*)\s', output.decode("utf-8"), re.IGNORECASE)
            openssl_version = match.group(1)
            full_version = full_version_match.group(1)
            if compare_versions(openssl_version, MIN_OPENSSL_VERSION):
                print_pass(f"OpenSSL Version {full_version}")
                CHECKS["openssl"] = Status.PASS
            else:
                print_fail(
                    f"OpenSSL Version {full_version} (Minimum {MIN_OPENSSL_VERSION} is required)"
                )
                CHECKS["openssl"] = Status.FAIL
        else:
            print_fail(
                "Could not verify OpenSSL version of the machine."
            )
            CHECKS["openssl"] = Status.FAIL
    except Exception:
        print_fail(
            "Could not verify OpenSSL version of the machine."
        )
        CHECKS["openssl"] = Status.FAIL


def check_and_apply_file_permissions():
    print("\nVerifying required file permissions...")
    # Mongo-Data directory owner
    try:
        if not os.path.exists("data/mongo-data"):
            print_fail(
                f"Could not locate data/mongo-data directory (Please run `git reset --hard HEAD && git pull` and re-run the script.)"
            )
            CHECKS["MONGO"] = Status.FAIL
        else:
            if platform.system().lower() not in ["darwin"]:
                command = f"sudo chown -R {MONGO_USER_ID}:{MONGO_USER_ID} data/mongo-data"
                set_directory_permission("data/mongo-data", command)
                print_pass(
                    f"Changing owner of data/mongo-data to user with uid {MONGO_USER_ID}"
                )
                CHECKS["MONGO"] = Status.PASS

            # mongo_data directory file
            try:
                command = "sudo chmod -R 744 data/mongo-data"
                set_directory_permission("data/mongo-data", command)
                print_pass(f"Adding read/write permissions to data/mongo-data")
                CHECKS["MONGO-FILE"] = Status.PASS
            except Exception as e:
                print_fail(
                    f"Error occurred while verifying file permissions for data/mongo-data"
                )
                CHECKS["MONGO-FILE"] = Status.FAIL
    except Exception as e:
        # print(e)
        print_fail(f"Error occurred while verifying owner of data/mongo-data")
        CHECKS["MONGO"] = Status.FAIL

    # mongo-init.sh file owner and permissions check
    try:
        if not os.path.exists("data/database-init/mongo-init.sh"):
            print_fail(
                f"Could not locate data/database-init/mongo-init.sh file "
                "(Please run `git reset --hard HEAD && git pull` and re-run the script.)"
            )
            CHECKS["MONGO-INIT"] = Status.FAIL
        else:
            if platform.system().lower() not in ["darwin"]:
                command = f"sudo chown -R {MONGO_USER_ID}:{MONGO_USER_ID} data/database-init"
                set_directory_permission("data/database-init", command)
                print_pass(
                    f"Changing owner of data/database-init/mongo-init.sh to user with uid {MONGO_USER_ID}"
                )
                CHECKS["MONGO-INIT"] = Status.PASS

            # mongo-init.sh permissions check
            try:
                command = "sudo chmod -R 775 data/database-init"
                set_directory_permission("data/database-init", command)
                print_pass(
                    "Adding read/write permissions to data/database-init/mongo-init.sh"
                )
                CHECKS["MONGO-INIT-FILE"] = Status.PASS
            except Exception as e:
                print_fail(
                    "Error occurred while verifying file permissions for data/database-init/mongo-init.sh"
                )
                CHECKS["MONGO-INIT-FILE"] = Status.FAIL
    except Exception as e:
        print_fail(
            "Error occurred while verifying owner of data/database-init/mongo-init.sh"
        )
        CHECKS["MONGO-INIT"] = Status.FAIL

    # Custom_plugins directory
    try:
        if not os.path.exists("data/custom_plugins"):
            print_fail(
                f"Could not locate data/custom_plugins directory (Please run `git reset --hard HEAD && git pull` and re-run the script.)"
            )
            CHECKS["CUSTOM_PLUGINS"] = Status.FAIL
        elif not os.path.exists("data/custom_plugins/__init__.py"):
            print_fail(
                f"Could not locate data/custom_plugins/__init__.py file (Please run `git reset --hard HEAD && git pull` and re-run the script.)"
            )
            CHECKS["CUSTOM_PLUGINS"] = Status.FAIL
        else:
            if platform.system().lower() not in ["darwin"]:
                command = "sudo chown -R 1001:1001 data/custom_plugins"
                set_directory_permission("data/custom_plugins", command)
                print_pass(
                    f"Changing owner of data/custom_plugins to user with uid 1001"
                )
                CHECKS["CUSTOM_PLUGINS"] = Status.PASS

            try:
                command = "sudo chmod -R 755 data/custom_plugins"
                set_directory_permission("data/custom_plugins", command)
                print_pass(
                    "Adding read/write permissions to data/custom_plugins"
                )
                CHECKS["CUSTOM_PLUGINS_FILE"] = Status.PASS
            except Exception as e:
                print_fail(
                    f"Error occurred while verifying file permissions for data/custom_plugins"
                )
                CHECKS["CUSTOM_PLUGINS_FILE"] = Status.FAIL

    except Exception as e:
        # print(e)
        print_fail(
            f"Error occurred while verifying file permissions for data/custom_plugins"
        )
        CHECKS["CUSTOM_PLUGINS"] = Status.FAIL

    # ssl_certs directory
    try:
        if not os.path.exists("data/ssl_certs"):
            print_fail(
                f"Could not locate data/ssl_certs directory (Please run `git reset --hard HEAD && git pull` and re-run the script.)"
            )
            CHECKS["SSL_CERTS"] = Status.FAIL
        else:
            if platform.system().lower() not in ["darwin"]:
                command = "sudo chown -R 1001:1001 data/ssl_certs"
                set_directory_permission("data/ssl_certs", command)
                print_pass(
                    f"Changing owner of data/ssl_certs to user with uid 1001"
                )
                CHECKS["SSL_CERTS"] = Status.PASS

            command = "sudo chmod 755 data/ssl_certs"
            set_directory_permission("data/ssl_certs", command)
            print_pass(f"Adding read/write permissions to data/ssl_certs")
            CHECKS["SSL_CERTS"] = Status.PASS

        if os.path.exists("data/ssl_certs/cte_cert.crt"):
            command = "sudo chmod 644 data/ssl_certs/cte_cert.crt"
            set_directory_permission("data/ssl_certs/cte_cert.crt", command)
            print_pass(
                f"Adding read permissions to data/ssl_certs/cte_cert.crt"
            )

        if os.path.exists("data/ssl_certs/cte_cert_key.key"):
            command = "sudo chmod 644 data/ssl_certs/cte_cert_key.key"
            set_directory_permission(
                "data/ssl_certs/cte_cert_key.key", command
            )
            print_pass(
                f"Adding read permissions to data/ssl_certs/cte_cert_key.key"
            )

    except Exception as e:
        print_fail(
            f"Error occurred while verifying file permissions for data/ssl_certs"
        )
        CHECKS["SSL_CERTS"] = Status.FAIL

    # rabbitmq directory
    try:
        if not os.path.exists("data/rabbitmq/data"):
            print_fail(
                "Could not locate data/rabbitmq/data directory (Please run `git reset --hard HEAD && git pull` and re-run the script.)"
            )
            CHECKS["RABBITMQ"] = Status.FAIL
        else:
            if platform.system().lower() not in ["darwin"]:
                command = "sudo chown -R 1001:1001 data/rabbitmq"
                set_directory_permission("data/rabbitmq", command)
                print_pass(
                    "Changing owner of data/rabbitmq to user with uid 1001"
                )
                CHECKS["RABBITMQ"] = Status.PASS
            command = "sudo chmod -R 744 data/rabbitmq"
            set_directory_permission("data/rabbitmq", command)
            command = "sudo chmod 755 data/rabbitmq"
            set_directory_permission("data/rabbitmq", command)
            print_pass("Adding read permissions to data/rabbitmq")
            CHECKS["RABBITMQ"] = Status.PASS
    except Exception:
        print_fail(
            "Error occurred while verifying file permissions/owner information for data/rabbitmq directory"
        )
        CHECKS["RABBITMQ"] = Status.FAIL

    try:
        if not os.path.exists("data/ca_certs"):
            print_fail(
                f"Could not locate data/ca_certs directory (Please run `git reset --hard HEAD && git pull` and re-run the script.)"
            )
            CHECKS["ca_certs"] = Status.FAIL
        else:
            command = "sudo chmod -R 644 data/ca_certs/"
            set_directory_permission("data/ca_certs", command)
            command = "sudo chmod 755 data/ca_certs"
            set_directory_permission("data/ca_certs", command)
            print_pass(f"Adding read permissions to data/ca_certs")
            CHECKS["ca_certs"] = Status.PASS
    except Exception as e:
        print_fail(
            f"Error occurred while verifying file permissions for data/ca_certs"
        )
        CHECKS["ca_certs"] = Status.FAIL

    # start script
    try:
        if not os.path.exists("./start"):
            print_fail(
                f"Could not locate start script (Please run `git reset --hard HEAD && git pull` and re-run the script.)"
            )
            CHECKS["START"] = Status.FAIL
        else:
            command = "sudo chmod 555 ./start"
            set_directory_permission("start", command)
            print_pass(f"Adding execute permissions to start script")
            CHECKS["START"] = Status.PASS
    except Exception as e:
        # print(e)
        print_fail(
            f"Error occurred while verifying file permissions for start script"
        )
        CHECKS["START"] = Status.FAIL

    # stop script
    try:
        if not os.path.exists("./stop"):
            print_fail(
                f"Could not locate stop script (Please run `git reset --hard HEAD && git pull` and re-run the script.)"
            )
            CHECKS["STOP"] = Status.FAIL
        else:
            command = "sudo chmod 555 ./stop"
            set_directory_permission("stop", command)
            print_pass(f"Adding execute permissions to stop script")
            CHECKS["STOP"] = Status.PASS
    except Exception as e:
        # print(e)
        print_fail(
            f"Error occurred while verifying file permissions for stop script"
        )
        CHECKS["STOP"] = Status.FAIL


def validate_port(port):
    try:
        if port == "":
            return True
        port = int(port)
        if 1 <= port <= 65535:
            return True
        return False
    except Exception as e:
        return False


def check_port(port):
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        result = sock.connect_ex(("127.0.0.1", port))
        if result == 0:
            if is_ui_running:
                print_warning("The UI container is already running.")
                CHECKS["UI Port Check"] = Status.PASS
                return True
            else:
                print_fail(f"Port {port} is already in use.\033[0;37m\n")
                CHECKS["UI Port Check"] = Status.FAIL
                return False
        else:
            print_pass(f"Port {port} is available.\n")
            CHECKS["UI Port Check"] = Status.PASS
            return True
    except Exception as e:
        # print(e)
        print_warning(f"Could not verify Port information of the machine]n")
        CHECKS["UI Port Check"] = Status.NOT_VERIFIED


def pull_from_github():
    myenv = os.environ.copy()
    myenv["LC_ALL"] = "C"
    print("\nChecking for local changes..")
    pr1 = subprocess.Popen(
        ["git", "diff", "-G."],
        cwd=os.getcwd(),
        shell=False,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        env=myenv,
    )
    (out, error) = pr1.communicate()
    out = out.decode("utf-8")
    error = error.decode("utf-8")

    print(out)

    if error != "":
        print(f"\nError while checking for git diff. {error}\n")
    if out != "":
        print(
            "\n\033[1;31mThere are some local changes that might affect the installation. Can not proceed further. Please Remove the local changes and re-run the script.\033[0;37m\n"
        )
        exit(1)


def migrate_mongo():
    print("\nVerifying mongo-data directory...")
    if os.path.exists("data/mongo-data/"):
        files = os.listdir("data/mongo-data/")
        files = [x for x in files if not x.startswith(".")]

        if len(files) == 0 or "data" in files:
            print("mongo-data directory structure is already updated... ")
            return

        if not os.path.exists("data/mongo-data/data/db/"):
            print("\nCreating data/mongo-data/data/db directory...")
            os.makedirs("data/mongo-data/data/db/", mode=0o744)

        try:
            for _file in files:
                path_name = f"data/mongo-data/{_file}"
                if os.path.isdir(path_name):
                    shutil.copytree(
                        path_name, f"data/mongo-data/data/db/{_file}"
                    )
                else:
                    shutil.copy(path_name, "data/mongo-data/data/db/")
            print("mongo-data directory structure updated successfully")

            # Change owner to 1001 after copying the data
            if platform.system().lower() not in ["darwin"]:
                command = f"sudo chown -R {MONGO_USER_ID}:{MONGO_USER_ID} data/mongo-data"
                set_directory_permission("data/mongo-data", command)
        except Exception as exc:
            print(f"Error while migrating mongo-data: {exc}")
    else:
        print_fail(
            f"Could not locate data/mongo-data directory (Please run `git reset --hard HEAD && git pull` and re-run the script.)"
        )
        exit(1)


def copy_env(inputs):
    while True:
        if AVAILABLE_INPUTS.get("DESTINATION_PATH", "") == "":
            destination = input(
                "> Enter the destination path (e.g. './backup_env'): "
            ).strip()
        else:
            destination = input(
                f"\n> Enter the destination path for backup of .env (Current: \"{AVAILABLE_INPUTS['DESTINATION_PATH']}\"): "
            ).strip()
        destination = (
            AVAILABLE_INPUTS.get("DESTINATION_PATH", "")
            if destination == ""
            else destination
        )
        if destination.strip() == get_secret_location(inputs).strip():
            print_warning(
                "Can not use this path as the backup location. Please enter a different path."
            )
            continue
        AVAILABLE_INPUTS["DESTINATION_PATH"] = destination
        put_env_variable(AVAILABLE_INPUTS)
        command = f"cp -r .env {destination}"
        try:
            p = subprocess.Popen(
                command.split(),
                shell=False,
                stderr=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stdin=subprocess.PIPE,
            )
            out, err = p.communicate()
            if len(err) <= 0:
                print("backup completed...")
                break
            else:
                AVAILABLE_INPUTS.get("DESTINATION_PATH", "") == ""
                raise Exception(err.decode("utf-8"))
        except Exception as e:
            if p:
                p.kill()
            print(f"Error occurred while taking backup. Error: {e}")
            continue


def take_env_backup(inputs):
    if AVAILABLE_INPUTS.get("DESTINATION_PATH", "") == "":
        isBackup = (
            input("\n\n> Do you want to take backup of .env file? [y/n]: ")
            .strip()
            .lower()
        )
        if isBackup == "y" or isBackup == "yes":
            copy_env(inputs)
    else:
        copy_env(inputs)


def get_total_physical_memory():
    try:
        if sys.platform.startswith("linux"):
            with open("/proc/meminfo", "r") as mem_info:
                for line in mem_info:
                    if line.startswith("MemTotal"):
                        total_memory = int(line.split()[1]) * 1024
                        return total_memory
        elif sys.platform.startswith("darwin"):
            memory_info = os.popen("sysctl hw.memsize").read().strip()
            total_memory = int(memory_info.split(":")[1].strip())
            return total_memory
        return None
    except Exception:
        pass


def assign_memory_to_rabbitmq_container():
    try:
        mem_bytes = get_total_physical_memory()
        if not mem_bytes:
            return
        mem_mib = mem_bytes / (1024**2)

        AVAILABLE_INPUTS["RABBITMQ_RAM_RESOURCES"] = round(mem_mib * (6 / 32))
        AVAILABLE_INPUTS["MONGODB_RAM_RESOURCES"] = round(mem_mib * (4 / 32))
        AVAILABLE_INPUTS["CORE_RAM_RESOURCES"] = round(mem_mib * (18 / 32))
        AVAILABLE_INPUTS["UI_RAM_RESOURCES"] = 256
    except Exception:
        pass


def validate_jwt_secret(value):
    if not value:
        return False, "JWT Secret should not be empty. Please try again."
    restricted_chars = {"\\", "/", " ", "'", '"', "?", "&", "\t"}
    for char in restricted_chars:
        if char in value:
            return False, (
                "JWT Secret can not contain \\ / space "
                "tab ' \" ? & Please try again."
            )
    return True, "Valid"


def change_maintenance_password(raw_text: str, forward=True):
    try:
        CE_SETUP_ID = None
        CE_HEX_CODE = None
        CE_IV = None
        if not AVAILABLE_INPUTS.get("CE_SETUP_ID", ""):
            CE_SETUP_ID = generate_ce_setup_id()
            AVAILABLE_INPUTS["CE_SETUP_ID"] = f'"{CE_SETUP_ID}"'
            AVAILABLE_INPUTS["CE_HEX_CODE"] = os.urandom(8).hex().upper()
            AVAILABLE_INPUTS["CE_IV"] = os.urandom(16).hex()
        CE_HEX_CODE = AVAILABLE_INPUTS["CE_HEX_CODE"]
        CE_IV = AVAILABLE_INPUTS["CE_IV"]
        CE_SETUP_ID = AVAILABLE_INPUTS["CE_SETUP_ID"].strip('"')
        command = f"""echo -n '{CE_SETUP_ID}' | openssl dgst -sha256 -hex | awk '{{print $2}}'"""
        process = subprocess.Popen(
            command,
            shell=True,
            stderr=subprocess.PIPE,
            stdout=subprocess.PIPE,
        )
        out, err = process.communicate()
        if process.returncode == 0:
            processed_stream = out.decode().strip()
            # generate mpass
            if forward:
                second_command = f"""echo "{raw_text}" | openssl enc -aes-256-cbc -a -S {CE_HEX_CODE} -K "{processed_stream}" -iv {CE_IV} -pbkdf2 -iter 10000"""
                second_process = subprocess.Popen(
                    second_command,
                    shell=True,
                    stderr=subprocess.PIPE,
                    stdout=subprocess.PIPE,
                )
                sec_out, sec_err = second_process.communicate()
                if second_process.returncode == 0:
                    return sec_out.decode().strip()
                else:
                    raise Exception(f"{sec_err.decode('utf-8')}\n")
            else:
                third_command = f"""echo "{raw_text}" | openssl enc -aes-256-cbc -d -a -S {CE_HEX_CODE} -K "{processed_stream}" -iv {CE_IV} -pbkdf2 -iter 10000"""
                third_process = subprocess.Popen(
                    third_command,
                    shell=True,
                    stderr=subprocess.PIPE,
                    stdout=subprocess.PIPE,
                )
                third_out, third_err = third_process.communicate()
                if third_process.returncode == 0:
                    return third_out.decode().strip()
                else:
                    raise Exception(f"{third_err.decode('utf-8')}\n")
        else:
            raise Exception(f"{err.decode('utf-8')}\n")
    except Exception as e:
        raise Exception(
            f"Error occurred while processing environment variables. Error: {e}"
        )


def ask_for_config_params():
    # Ask for Protocol
    protocol = ""
    is_ssl_enabled = check_for_certs()
    if not is_ssl_enabled:
        while protocol not in ["http", "https"]:
            protocol = (
                input(
                    "\nDo you want to access CE over HTTP, or HTTPS (HTTPS is recommended)? "
                )
                .strip()
                .lower()
            )
            if protocol == "http":
                print("Accessing CE over HTTP is not recommended\n")
                confim = (
                    input("Do you still want to access CE over HTTP? (y/yes) ")
                    .strip()
                    .lower()
                )
                if confim not in ["y", "yes"]:
                    protocol = ""
                    continue
                else:
                    DEFAULT_INPUTS["ENABLE_TLS_V_1_2"]["default"] = "TLSv1.3"
                    DEFAULT_INPUTS["ENABLE_TLS_V_1_2"]["skip"] = True
                    AVAILABLE_INPUTS["UI_PROTOCOL"] = "http"
            elif protocol == "https":
                AVAILABLE_INPUTS["UI_PROTOCOL"] = "https"
                DEFAULT_INPUTS["UI_PORT"]["default"] = 443
                is_ssl_enabled = (
                    check_for_certs()
                )  # Checking if SSL is enabled or not
                if not is_ssl_enabled:
                    create_self_signed_ssl_certs()

                message = "\033[1;37mReplace ./data/ssl_certs/cte_cert.crt and ./data/ssl_certs/cte_cert_key.key files with your custom certificate and key files respectively to use custom SSL certificates.\033[0;37m"
                if AVAILABLE_INPUTS.get("HA_NFS_DATA_DIRECTORY"):
                    message = message.replace(
                        "./data/ssl_certs/",
                        f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/config/ssl_certs/",
                    )
                print(message)
            else:
                print("Invalid input... Valid inputs are 'http' or 'https'.\n")
    else:
        DEFAULT_INPUTS["UI_PORT"]["default"] = 443

    print()

    # Ask for all configuration parameters
    for key, item in DEFAULT_INPUTS.items():
        data = ""
        if not item["skip"]:
            if key not in AVAILABLE_INPUTS:
                if item["help"]:
                    print(item["help"])
                if item.get("mandatory", False):
                    user_input = item.get("user_input")
                    if key == "JWT_SECRET":
                        data = ""
                        while data == "":
                            data = getpass(f"> {user_input}: ").strip()
                            result, message = validate_jwt_secret(data)
                            if not result:
                                print(f"{message}\n")
                                data = ""
                                continue
                    elif (
                        "IS_MPASS_CONFIGURED" in AVAILABLE_INPUTS
                        and key == "MAINTENANCE_PASSWORD"
                        and os.path.exists(get_secret_location(AVAILABLE_INPUTS))
                    ):
                        pass
                    elif key == "MAINTENANCE_PASSWORD":
                        data = "a"
                        confirm_data = "b"
                        while data != confirm_data or len(data) == 0:
                            data = "a"
                            confirm_data = "b"
                            data = getpass(f"> {user_input}: ").strip()
                            if data == "":
                                print(
                                    "Maintenance password can not be empty. Please try again.\n"
                                )
                                continue

                            if (
                                ("\\" in data)
                                or ("/" in data)
                                or ("'" in data)
                                or ('"' in data)
                                or (" " in data)
                            ):
                                print(
                                    "Maintenance password can not contain \\ / space ' \" Please try again.\n"
                                )
                                continue

                            confirm_data = getpass(
                                f"\n> Confirm maintenance password: "
                            ).strip()
                            if data != confirm_data:
                                print(
                                    "Maintenance password and Confirm maintenance password do not match. Please try again.\n"
                                )
                        data = f"'{data}'"
                    else:
                        data = input(f"> {user_input}: ").strip()
                else:
                    user_input = item.get("user_input")
                    if user_input:
                        if key == "UI_PORT":
                            i = 0
                            while True:
                                if i >= 3:
                                    print(
                                        "\033[1;37mPlease make sure the port on which you want to access the Netskope CE UI is available and Re-run the script.\033[0;37m"
                                    )
                                    exit(1)
                                data = input(
                                    f"> {user_input} (Default: \"{item['default']}\"): "
                                ).strip()
                                if validate_port(data):
                                    data = (
                                        item["default"] if data == "" else data
                                    )
                                    if check_port(int(data)):
                                        print(
                                            "\033[1;37mNOTE: This port will be used to access the Netskope CE UI. Please make sure that inbound traffic to this port is allowed.\n\033[0;37m"
                                        )
                                        break
                                else:
                                    print(
                                        "Invalid port provided... Port should be within 1 to 65535 range...\n"
                                    )
                                i += 1
                        else:
                            data = input(
                                f"> {user_input} (Default: \"{item['default']}\"): "
                            ).strip()
                    else:
                        data = input(
                            f"> Enter {key} (Default: \"{item['default']}\"): "
                        ).strip()

            else:
                if key != "MAINTENANCE_PASSWORD":
                    if item["help"]:
                        print(item["help"])
                    user_input = item.get("user_input", None)
                    if user_input:
                        if key == "JWT_SECRET":
                            data = ""
                            while data == "":
                                data = getpass(f"> {user_input}: ").strip()
                                result, message = validate_jwt_secret(data)
                                if not result:
                                    print(f"{message}\n")
                                    data = ""
                                    continue
                        elif key == "UI_PORT":
                            i = 0
                            while True:
                                if i >= 3:
                                    print(
                                        "\033[1;37mPlease make sure the port on which you want to access the Netskope CE UI is available and Re-run the script.\033[0;37m"
                                    )
                                    exit(1)
                                data = input(
                                    f'> {user_input} (Current: "{AVAILABLE_INPUTS[key]}"): '
                                ).strip()
                                if validate_port(data):
                                    data = (
                                        AVAILABLE_INPUTS[key]
                                        if data == ""
                                        else data
                                    )
                                    if check_port(int(data)):
                                        print(
                                            "\033[1;37mNOTE: This port will be used to access the Netskope CE UI. Please make sure that inbound traffic to this port is allowed.\n\033[0;37m"
                                        )
                                        break
                                else:
                                    print(
                                        "Invalid port provided... Port should be within 1 to 65535 range...\n"
                                    )
                                i += 1
                        else:
                            data = input(
                                f'> {user_input} (Current: "{AVAILABLE_INPUTS[key]}"): '
                            ).strip()
                    else:
                        data = input(
                            f'> Enter {key} (Current: "{AVAILABLE_INPUTS[key]}"): '
                        ).strip()
            print("")
        data = data.strip() if isinstance(data, str) else data
        if not data:
            if key not in AVAILABLE_INPUTS:
                data = item["default"]
            else:
                data = AVAILABLE_INPUTS[key]
        data = data.strip() if isinstance(data, str) else data
        if key == "MAINTENANCE_PASSWORD_ESCAPED":
            data = urllib.parse.quote_plus(
                AVAILABLE_INPUTS["MAINTENANCE_PASSWORD"].strip("'")
            )

        if key == "ENABLE_TLS_V_1_2":
            if data.lower() in ["y", "yes"]:
                data = '"TLSv1.2 TLSv1.3"'
            else:
                data = "TLSv1.3"
        AVAILABLE_INPUTS[key] = data

        if key == "PULL_THREADS":
            AVAILABLE_INPUTS[key] = item.get("default", 4)

        if (
            key == "RABBITMQ_COOKIE"
            and not AVAILABLE_INPUTS["RABBITMQ_COOKIE"]
        ):
            length = 32
            chars = string.ascii_letters + string.digits
            AVAILABLE_INPUTS["RABBITMQ_COOKIE"] = "".join(
                random.choice(chars) for _ in range(length)
            )


def _validate_ip(ip, debug=True):
    try:
        ipaddress.ip_address(ip)
    except ValueError:
        if debug:
            print(
                "Invalid IP address provided. Please provide a valid IP address."
            )
        return False
    return True


def _validate_ips(ips):
    ips = list(filter(None, [x.strip() for x in ips.split(",")]))
    for ip in ips:
        if not _validate_ip(ip):
            return False
    return True


def _validate_current_node(ip):
    if ip not in AVAILABLE_INPUTS.get("HA_IP_LIST", "").split(","):
        print(
            "Provided input doesn't match with any of the listed node addresses."
        )
        return False
    return True

def recursive_change_permissions(root_dir, dir_perms=0o755, file_perms=0o664):
    for dirpath, dirnames, filenames in os.walk(root_dir):
        for dirname in dirnames:
            dir_full_path = os.path.join(dirpath, dirname)
            os.chmod(dir_full_path, dir_perms)
        for filename in filenames:
            file_full_path = os.path.join(dirpath, filename)
            os.chmod(file_full_path, file_perms)

def recursive_chown(path, uid, gid):
    os.chown(path, uid, gid)
    for root, dirs, files in os.walk(path):
        for dir in dirs:
            os.chown(os.path.join(root, dir), uid, gid)
        for file in files:
            os.chown(os.path.join(root, file), uid, gid)


def create_required_files(location):
    if not os.path.exists(f"{location}/config"):
        os.mkdir(f"{location}/config")
    os.chmod(f"{location}/config", 0o744)

    if not os.path.exists(f"{location}/config/ssl_certs"):
        os.mkdir(f"{location}/config/ssl_certs")
    os.chmod(f"{location}/config/ssl_certs", 0o755)
    os.chown(f"{location}/config/ssl_certs", 1001, 1001)

    if os.path.exists(f"{location}/config/ssl_certs/cte_cert.crt"):
        os.chmod(f"{location}/config/ssl_certs/cte_cert.crt", 0o644)

    if os.path.exists(f"{location}/config/ssl_certs/cte_cert_key.key"):
        os.chmod(f"{location}/config/ssl_certs/cte_cert_key.key", 0o644)

    if not os.path.exists(f"{location}/config/ca_certs"):
        os.mkdir(f"{location}/config/ca_certs")
    os.chmod(f"{location}/config/ca_certs", 0o755)

    if not os.path.exists(f"{location}/config/ca_certs/.keep"):
        open(f"{location}/config/ca_certs/.keep", "w").close()
    os.chmod(f"{location}/config/ca_certs/.keep", 0o644)

    if not os.path.exists(f"{location}/repos"):
        os.mkdir(f"{location}/repos")
    recursive_change_permissions(f"{location}/repos")
    recursive_chown(f"{location}/repos", 1001, 1001)

    if not os.path.exists(f"{location}/plugins"):
        os.mkdir(f"{location}/plugins")
    recursive_change_permissions(f"{location}/plugins")
    recursive_chown(f"{location}/plugins", 1001, 1001)

    if not os.path.exists(f"{location}/custom_plugins"):
        os.mkdir(f"{location}/custom_plugins")
    recursive_change_permissions(f"{location}/custom_plugins")
    recursive_chown(f"{location}/custom_plugins", 1001, 1001)

    if not os.path.isfile(f"{location}/config/mongo_replica.key"):
        with open(f"{location}/config/mongo_replica.key", "w") as fp:
            fp.write(b64encode(token_bytes(60)).decode())
    os.chmod(f"{location}/config/mongo_replica.key", 0o400)
    os.chown(
        f"{location}/config/mongo_replica.key", MONGO_USER_ID, MONGO_USER_ID
    )


def create_persistent_dirs(location="./data"):
    if not os.path.exists(f"{location}/repos"):
        os.mkdir(f"{location}/repos")
    recursive_change_permissions(f"{location}/repos")
    recursive_chown(f"{location}/repos", 1001, 1001)

    if not os.path.exists(f"{location}/plugins"):
        os.mkdir(f"{location}/plugins")
    recursive_change_permissions(f"{location}/plugins")
    recursive_chown(f"{location}/plugins", 1001, 1001)

    if not os.path.exists(f"{location}/custom_plugins"):
        os.mkdir(f"{location}/custom_plugins")
    recursive_change_permissions(f"{location}/custom_plugins")
    recursive_chown(f"{location}/custom_plugins", 1001, 1001)


def update_yaml_file(filename):
    # Import Yaml module for HA.
    import yaml

    with open(f"{filename}.yml", "r") as file:
        compose_data = yaml.load(file, Loader=yaml.SafeLoader)

    # Add hosts for connectivity
    hosts_list = AVAILABLE_INPUTS["HA_IP_LIST"].split(",")

    # Update hostname of the RabbitMQ container
    for index, var in enumerate(
        compose_data["services"]["rabbitmq-stats"]["environment"]
    ):
        if "RABBITMQ_NODENAME" in var:
            compose_data["services"]["rabbitmq-stats"]["environment"][
                index
            ] = var.replace(
                "rabbit@rabbitmq-stats",
                f"rabbit@{AVAILABLE_INPUTS['HA_CURRENT_NODE']}",
            )
    compose_data["services"]["rabbitmq-stats"]["environment"].append(
        "RABBITMQ_USE_LONGNAME=true"
    )

    for service in compose_data["services"]:
        compose_data["services"][service]["env_file"] = [
            f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/config/.env",
            "${LOCATION}",
        ]

    # Add Ports
    compose_data["services"]["rabbitmq-stats"]["ports"] = [
        "4369:4369",
        "5672:5672",
        "15672:15672",
        "25672:25672",
        "35672:35672",
    ]
    compose_data["services"]["mongodb-primary"]["ports"] = ["27017:27017"]

    # Update mongo service for authentication using mongo_replica.key
    compose_data["services"]["mongodb-primary"]["volumes"].append(
        f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/config/mongo_replica.key:/data/mongo_replica.key:z"
    )
    compose_data["services"]["mongodb-primary"][
        "entrypoint"
    ][2] += " --bind_ip_all --replSet mongo_replica_set --keyFile /data/mongo_replica.key"

    # Update connection strings and add required variables
    compose_data["services"]["core"]["environment"].extend(
        [
            "HA_IP_LIST=${HA_IP_LIST}",
            "UI_PROTOCOL=${UI_PROTOCOL}",
            "UI_PORT=${UI_PORT}",
        ]
    )

    # Update the certificate paths
    for index, volume in enumerate(compose_data["services"]["ui"]["volumes"]):
        compose_data["services"]["ui"]["volumes"][index] = volume.replace(
            "./data/ssl_certs",
            f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/config/ssl_certs",
        )
    for index, volume in enumerate(
        compose_data["services"]["core"]["volumes"]
    ):
        volume = volume.replace(
            "./data/ca_certs",
            f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/config/ca_certs",
        )
        volume = volume.replace(
            "./data/custom_plugins",
            f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/custom_plugins",
        )
        compose_data["services"]["core"]["volumes"][index] = volume

    compose_data["volumes"] = {
        "nfs_repos": {
            "driver": "local",
            "driver_opts": {
                "type": "none",
                "o": "bind",
                "device": f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/repos",
            },
        },
        "nfs_plugins": {
            "driver": "local",
            "driver_opts": {
                "type": "none",
                "o": "bind",
                "device": f"{AVAILABLE_INPUTS['HA_NFS_DATA_DIRECTORY']}/plugins",
            },
        },
    }

    with open(f"{filename}-ha.yml", "w") as file:
        yaml.dump(
            compose_data,
            file,
            default_flow_style=False,
            sort_keys=False,
            Dumper=yaml.SafeDumper,
        )


def ask_for_ha_values(primary=False):
    # Ask for IP list
    key = "HA_IP_LIST"
    if primary:
        message = (
            "> Enter comma separated IP list to connect the machines for HA."
            f" (Current: \"{AVAILABLE_INPUTS.get(key, '')}\"): "
        )
        while True:
            data = input(message).strip() or AVAILABLE_INPUTS.get(key, "")
            data = ",".join(
                list(filter(None, [i.strip() for i in data.split(",")]))
            )
            if not data:
                print(
                    "Required value is not provided. Please provide a valid value."
                )
                continue
            AVAILABLE_INPUTS[key] = data
            break
    else:
        print(
            f"The HA is enabled. Current HA IP list: {AVAILABLE_INPUTS.get(key)}"
        )

    # Ask for current node info
    key = "HA_CURRENT_NODE"
    message = f"> Enter ip address of current node. (Current: \"{AVAILABLE_INPUTS.get(key, '')}\"): "
    while True:
        data = input(message).strip() or AVAILABLE_INPUTS.get(key, "")
        if not data:
            print(
                "Required value is not provided. Please provide a valid value."
            )
            continue
        if _validate_current_node(data):
            AVAILABLE_INPUTS[key] = data
            if primary:
                AVAILABLE_INPUTS["HA_PRIMARY_NODE_IP"] = data
            break
        print(
            "The provided values does not exist in above list. Please provide a valid value."
        )


def generate_dependency_message(version_dict):
    required_versions = []
    for dep, versions in version_dict.items():
        version_string = []
        if "min_version" in versions:
            version_string.append(f">={versions['min_version']}")
        if "max_version" in versions:
            version_string.append(f"<={versions['max_version']}")
        required_versions.append(dep + ", ".join(version_string))
    return " | ".join(required_versions)


def check_python_prerequisites():
    print("\nVerifying the Python prerequisites...")
    try:
        version_dict = {
            "pyyaml": {"min_version": "6.0.0"},
            "python-dotenv": {"min_version": "0.20.0", "max_version": "1.0.0"},
            "pymongo": {"min_version": "4.6.3", "max_version": "4.7.3"},
        }
        import pkg_resources

        for package, version in version_dict.items():
            module_version = pkg_resources.get_distribution(package).version
            if "min_version" in version:
                if not compare_versions(
                    module_version, version["min_version"]
                ):
                    raise Exception(
                        f"Invalid version of the '{package}' package"
                    )
            if "max_version" in version:
                if not compare_versions(
                    version["max_version"], module_version
                ):
                    raise Exception(
                        f"Invalid version of the '{package}' package"
                    )
    except Exception as err:
        print_fail(
            f"{err}. Please make sure the dependencies ({generate_dependency_message(version_dict)}) "
            "are satisfied before running ./setup script."
        )
        exit(1)
    print_pass("Python prerequisites verified successfully.")


def set_up_ha_values():
    global is_ha
    # Base version for HA support is 5.0.0
    install_version = AVAILABLE_INPUTS["INSTALL_VERSION"]
    if install_version < MIN_HA_SUPPORTED_VERSION:
        return

    while True:
        try:
            is_ha = strtobool(
                input("\n> Do you want to setup HA Parameters? [y/n]: ")
                .strip()
                .lower()
            )
        except Exception:
            print("Invalid input. Please provide a valid input.")
            continue
        if not is_ha:
            AVAILABLE_INPUTS.pop("HA_NFS_DATA_DIRECTORY", None)
            AVAILABLE_INPUTS.pop("HA_IP_LIST", None)
            AVAILABLE_INPUTS.pop("HA_CURRENT_NODE", None)
            AVAILABLE_INPUTS.pop("HA_PRIMARY_NODE_IP", None)
            # previously we have HA and now we want to setup on-prem/OVA.
            if (
                "IS_MPASS_CONFIGURED" in AVAILABLE_INPUTS.keys()
                and AVAILABLE_INPUTS.get("LOCATION", None)
                and AVAILABLE_INPUTS.get("LOCATION", None)
                not in [".env.keys", "/etc/.env.keys"]
            ):
                dest_location = None
                env_file_location = None
                if ce_as_vm_check():
                    dest_location = "/etc/"
                    env_file_location = "/etc/.env.keys"
                else:
                    dest_location = "."
                    env_file_location = ".env.keys"
                command = f"sudo mv {AVAILABLE_INPUTS.get('LOCATION', None)} {dest_location}"
                execute_shell_command(command)
                AVAILABLE_INPUTS["LOCATION"] = env_file_location
            return
        break

    check_python_prerequisites()

    while True:
        location = input(
            f"> Please provide the location of the NFS mount directory (Current: '{AVAILABLE_INPUTS.get('HA_NFS_DATA_DIRECTORY', '')}'): "
        ).strip().rstrip("/") or AVAILABLE_INPUTS.get(
            "HA_NFS_DATA_DIRECTORY", ""
        )
        if os.path.isdir(location):
            # previously we have on-prem / OVA and now we want to setup HA.
            if is_ha and AVAILABLE_INPUTS.get("LOCATION", None) in [
                ".env.keys",
                "/etc/.env.keys",
            ]:
                command = (
                    f"sudo mv {AVAILABLE_INPUTS.get('LOCATION')} {location}/"
                )
                execute_shell_command(command)
                AVAILABLE_INPUTS["LOCATION"] = f"{location}/.env.keys"
            break
        print("The provided path doesn't exist. Please provide a valid path.")
    try:
        get_all_existed_env_variable(
            f"{location}/config/.env", override=False
        )  # Get env variables from shared location
    except Exception:
        pass  # For fresh setup, shared .env doesn't exist
    AVAILABLE_INPUTS["HA_NFS_DATA_DIRECTORY"] = location

    create_required_files(location)
    ask_for_ha_values(primary=True)

    update_yaml_file("docker-compose")
    if not ce_as_vm_check():
        update_yaml_file("podman-compose")


def parse_selinux_status(output):
    selinux_info = {}
    lines = output.splitlines()
    for line in lines:
        key, value = map(str.strip, line.split(":"))
        selinux_info[key] = value
    return selinux_info


def mongo_feature_compatibility(maintenance_password):
    """
    Make mongo data compatibility when migrating from older to newer version.
    """
    is_mongo_compatible = (
        True
        if get_existing_variable_value(".env", "MONGO_COMPATIBILITY") == "True"
        else False
    )
    mongo_data_path = "data/mongo-data/data/db/"
    if not is_mongo_compatible and len(os.listdir(mongo_data_path)) > 1:
        print()
        print_warning(
            "The migration process for database is currently underway. Kindly wait for a few minutes."
        )
        run_temp_mongo_container_for_migration(
            maintenance_password,
            AVAILABLE_INPUTS.get("CORE_HTTP_PROXY", ""),
            AVAILABLE_INPUTS.get("CORE_HTTPS_PROXY", ""),
        )
    AVAILABLE_INPUTS["MONGO_COMPATIBILITY"] = True


def is_selinux_enabled():
    try:
        process = subprocess.Popen(
            ["sestatus"], stdout=subprocess.PIPE, stderr=subprocess.PIPE
        )
        stdout, _ = process.communicate()
        if process.returncode == 0:
            status_output = stdout.decode("utf-8").strip()
            selinux_info = parse_selinux_status(status_output)
            return (
                selinux_info.get("SELinux status", "").strip().lower()
                == "enabled"
            )
        else:
            return False
    except Exception:
        return False


def get_existing_variable_value(filepath, key_name):
    """Retrieve the value of an environment variable from a specific file path."""
    try:
        with open(filepath, "r") as f:
            if os.stat(filepath).st_size > 0:
                for line in f.readlines():
                    key, value = line.split("=", 1)
                    if key == key_name:
                        return value.strip()
    except Exception as e:
        raise Exception(
            f"Error occured while getting maintenance password. Error: {e}."
        )


def get_os_name_and_major_version():
    try:
        pretty_name = ""
        version_id = ""
        os_name = ""
        os_version = ""
        allow = False
        if os.path.exists("/etc/os-release"):
            with open("/etc/os-release", "r") as f:
                for line in f:
                    if line.startswith("PRETTY_NAME="):
                        pretty_name = line.split("=")[1].strip().strip('"')
                    elif line.startswith("VERSION_ID="):
                        version_id = line.split("=")[1].strip().strip('"')
                    if pretty_name and version_id:
                        break
            if "ubuntu" in pretty_name.lower():
                if version_id.split(".")[0] in ["20", "22"]:
                    os_version = version_id.split(".")[0]
                os_name = "Ubuntu"
                allow = True
            elif "centos" in pretty_name.lower():
                if version_id.split(".")[0] in ["7", "8"]:
                    os_version = version_id.split(".")[0]
                os_name = "CentOS"
            elif "red hat" in pretty_name.lower():
                if version_id.split(".")[0] in ["7", "8", "9"]:
                    os_version = version_id.split(".")[0]
                os_name = "RHEL"
                allow = True
        os_name_and_major_version = f"{os_name} {os_version}".strip()
        if os_name_and_major_version not in RECOMMENDED_HOST_OS and allow:
            print_warning(
                f"WARNING: CE is not supported on {pretty_name} version. Please switch to one of the supported version of OS. Supported OS: {RECOMMENDED_HOST_OS}"
            )
        elif os_name_and_major_version not in RECOMMENDED_HOST_OS:
            print(
                f"\033[1;31mCE is not supported on {pretty_name}. Please switch to one of the supported OS. Supported OS: {RECOMMENDED_HOST_OS} \033[0;37m"
            )
            if not should_ignore:
                exit(1)
        return os_name_and_major_version
    except Exception:
        pass
    return ""


def collect_host_platform_details():
    gcp = "gcp"
    aws = "aws"
    azure = "azure"
    vmware = "vmware"
    microsoft = "microsoft" # Hyper-V
    unknown = "unknown"

    base_url = "http://169.254.169.254"

    def check_platform(url, headers, machine_type):
        try:
            url_obj = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(url_obj, timeout=10) as response:
                if response.getcode() == 200:
                    return machine_type
                return False
        except Exception:
            return False

    def check_gcp():
        headers = {"Metadata-Flavor": "Google"}
        url = f"{base_url}/computeMetadata/v1/instance/hostname"

        return check_platform(url, headers, gcp)

    # check functon
    def check_ce_vm_marker_file():
        file_path = "/.cloud_exchange_vm.marker"
        if ce_as_vm_check():
            with open(file_path, "r") as file:
                lines = file.readlines()
                if lines:
                    return lines[0].strip().lower()

    def check_aws():
        # request for token
        headers = {"X-aws-ec2-metadata-token-ttl-seconds": "21600"}
        token_url = f"{base_url}/latest/api/token"
        TOKEN = None
        try:
            request = urllib.request.Request(
                token_url, headers=headers, method="PUT"
            )
            with urllib.request.urlopen(request, timeout=10) as response:
                TOKEN = response.read().decode("utf-8")

        except Exception:
            return False

        # request for metadata
        headers = {"X-aws-ec2-metadata-token": f"{TOKEN}"}
        metadata_url = f"{base_url}/latest/meta-data/local-hostname"
        return check_platform(metadata_url, headers, aws)

    def check_azure():
        headers = {"Metadata": "true"}
        url = f"{base_url}/metadata/instance?api-version=2023-11-15"

        return check_platform(url, headers, azure)

    def get_hypervisor_vendor():
        command = "lscpu"
        output = execute_shell_command(command).decode("utf-8")
        lines = output.split("\n")
        for line in lines:
            if "Hypervisor vendor" in line:
                return line.split(":")[-1].strip().lower()
        return False

    if check_gcp() == gcp:
        return gcp
    elif check_aws() == aws or check_ce_vm_marker_file() == aws:
        return aws
    elif check_azure() == azure or check_ce_vm_marker_file() == azure:
        return azure
    else:
        hypervisor_vendor = get_hypervisor_vendor()
        if hypervisor_vendor in [ vmware, microsoft ]:
            return hypervisor_vendor
        return unknown


def generate_ce_setup_id():
    return b64encode(token_bytes(32)).decode('utf-8')


def collect_host_details():
    try:
        print("\nChecking for host details, please wait for a few seconds...")
        global HOST_OS, COMPOSE_VERSION, CONTAINERIZATION_PLATFORM
        HOST_OS = get_os_name_and_major_version()
        AVAILABLE_INPUTS["CE_AS_VM"] = str(ce_as_vm_check())
        AVAILABLE_INPUTS["HA_ENABLED"] = "True" if is_ha else "False"
        AVAILABLE_INPUTS["CONTAINERIZATION_PLATFORM"] = (
            f'"{CONTAINERIZATION_PLATFORM}"'
        )
        AVAILABLE_INPUTS["COMPOSE_VERSION"] = f'"{COMPOSE_VERSION}"'
        AVAILABLE_INPUTS["HOST_OS"] = f'"{HOST_OS}"'
        AVAILABLE_INPUTS["PLATFORM_PROVIDER"] = str(
            collect_host_platform_details()
        )
    except Exception:
        pass

def check_and_apply_rabbitmq_flags():
    """
    Check and apply rabbitmq feature flags
    """
    try:
        print("\nChecking and applying rabbitmq feature flags, please wait for a few seconds...")
        CHECKS["RabbitMQ Feature Flags Check"] = Status.NOT_VERIFIED
        if not os.path.exists("data/rabbitmq/data/"):
            return
        for file in os.listdir("data/rabbitmq/data/"):
            if "feature_flags" in file:
                current_data = ""
                with open(f"data/rabbitmq/data/{file}", "r") as f:
                    current_data = f.read()
                if "stream_filtering" in current_data or "rabbitmq_4.0.0" in current_data:
                    continue
                with open(f"data/rabbitmq/data/{file}", "w") as f:
                    f.write(RABBITMQ_FEATURE_FLAGS)
        print_pass("Successfully applied rabbitmq feature flags")
        CHECKS["RabbitMQ Feature Flags Check"] = Status.PASS
    except Exception as e:
        print_warning(f"Error occurred while applying rabbitmq feature flags: {e}")
        print_warning(
            "You may need to delete the rabbitmq data from data/rabbitmq/data/ directory and before starting the Cloud Exchange."
        )

def run():
    try:
        global should_ignore
        parser = argparse.ArgumentParser(
            prog="./setup",
            description="Setup the environment for the Netskope CE.",
            epilog="For more info, please read the user guide.",
        )
        parser.add_argument(
            "-l",
            "--location",
            help="Location of the NFS mount directory.",
            required=False,
            default="",
        )
        parser.add_argument(
            "--ignore-failures",
            nargs="?",
            const=True,
            default=False,
            help="Ignore failures and continue.",
        )
        args = parser.parse_args()
        location = args.location.rstrip("/")
        should_ignore = args.ignore_failures

        print_banner()
        if not ce_as_vm_check():
            pull_from_github()
        if is_selinux_enabled():
            if not should_ignore:
                print_fail(
                    "SE Linux is enabled. Please DISABLE SE Linux for successful deployment of Netskope Cloud Exchange."
                )
                exit(1)
            else:
                print_warning(
                    "Ignoring the SE linux... '--ignore-failures' flag applied."
                )
        fetch_container_info()
        create_env_if_not_exist()
        if location:
            check_python_prerequisites()
            get_all_existed_env_variable()  # Get local env variables
            get_all_existed_env_variable(
                f"{location}/config/.env"
            )  # Get env variables from shared location
            get_all_existed_env_variable(f"{location}/config/.env.ceversion")

            AVAILABLE_INPUTS["HA_NFS_DATA_DIRECTORY"] = location
            ask_for_ha_values(primary=False)

            update_yaml_file("docker-compose")
            if not ce_as_vm_check():
                update_yaml_file("podman-compose")
        else:
            get_all_existed_env_variable()  # Get already exsting env variables
            location = AVAILABLE_INPUTS.get("HA_NFS_DATA_DIRECTORY", "")
            get_all_existed_env_variable(".env.ceversion")
            get_all_existed_env_variable(f"{location}/config/.env.ceversion")
            AVAILABLE_INPUTS.update(LATEST_TAG_AND_VERSION)
            if ce_as_vm_check():
                set_ce_version_for_vm()
            ask_for_initial_inputs()
            create_persistent_dirs()
            set_up_ha_values()
            location = AVAILABLE_INPUTS.get("HA_NFS_DATA_DIRECTORY")

        collect_host_details()
        check_prerequisites()
        migrate_mongo()
        check_and_apply_file_permissions()

        if (Status.FAIL in CHECKS.values()) or (
            Status.NOT_VERIFIED
            in [
                CHECKS.get("Podman-Plugin", None),
                CHECKS.get("Podman", None),
                CHECKS.get("Podman-Compose", None),
            ]
        ):
            print(
                "\n\n\033[1;31mInstallation failed. One or more prerequisite checks are not met. Please address the minimum requirements and re-run the setup script.\033[0;37m\n"
            )
            if should_ignore:
                print(
                    "\033[1;31mIgnoring the failures... '--ignore-failures' flag applied.\033[0;37m"
                )
            else:
                exit(1)

        if Status.NOT_VERIFIED in CHECKS.values():
            shouldContinue = (
                getpass(
                    "\n\n\033[1;93mOne or more prerequisite checks could not be verified. Press Enter to continue \033[0;37m"
                )
                .strip()
                .lower()
            )

        if not args.location.rstrip("/"):
            ask_for_config_params()

        code_tag_version = AVAILABLE_INPUTS.get("CORE_TAG", "").strip()
        if "3-latest" not in code_tag_version:
            # len == 1 as .gitkeep file will always be there in the ca_certs folder
            custom_cert_path = "./data/ca_certs"
            if location:
                custom_cert_path = f"{location}/config/ca_certs"
            if len(os.listdir(custom_cert_path)) == 1:
                # Ask for custom ca certs
                custom_ssl_confirm = (
                    input(
                        "\n> Do you want to provide custom CA certs? (y/n): "
                    )
                    .strip()
                    .lower()
                )
                if custom_ssl_confirm in ["y", "yes"]:
                    print(
                        f"\n\033[1;37mPlease add your certs to {custom_cert_path} and Re-run the script.\033[0;37m"
                    )
            else:
                print(
                    f"CA certificate successfully found in the {custom_cert_path} folder."
                )
        assign_memory_to_rabbitmq_container()
        mpass = None
        if AVAILABLE_INPUTS.get("MAINTENANCE_PASSWORD", ""):
            mpass = AVAILABLE_INPUTS.get("MAINTENANCE_PASSWORD", "")
        elif AVAILABLE_INPUTS.get("LOCATION", "") and os.path.exists(
            AVAILABLE_INPUTS["LOCATION"]
        ):
            mpass = get_existing_variable_value(
                AVAILABLE_INPUTS["LOCATION"], "MAINTENANCE_PASSWORD"
            )
        if AVAILABLE_INPUTS.get("CE_SETUP_ID", None) and not AVAILABLE_INPUTS.get("MAINTENANCE_PASSWORD", None):
            mpass = change_maintenance_password(mpass, False)
        mongo_feature_compatibility(mpass)

        put_env_variable(AVAILABLE_INPUTS)
        take_env_backup(AVAILABLE_INPUTS)
        check_and_apply_rabbitmq_flags()
        message = "\nSetup completed successfully...\n\nExecute this command to start the CE:\n  >"
        if location:
            put_env_variable(AVAILABLE_INPUTS, f"{location}/config/.env")
            message = "\nSetup completed successfully...\n\nExecute this command in primary node to start the CE:\n  >"

        print(f"{message} sudo ./start")
        print("\nPlease re-run the setup script to update any parameter.\n")

    except KeyboardInterrupt:
        put_env_variable(AVAILABLE_INPUTS)
        if location:
            put_env_variable(AVAILABLE_INPUTS, f"{location}/config/.env")
        print(
            "\nSetup stopped... The entered configurations will be saved...\n"
        )
    except Exception as e:
        print(e)

    print(
        "\nWarning: It is recommended to take an external backup of the .env file located in this directory."
    )


if __name__ == "__main__":
    run()
